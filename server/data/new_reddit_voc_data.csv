index,source,url,title,body,created_at,upvote
0,aws,https://i.redd.it/xnblsjm6v5371.png,"The recent ""all the ways to run containers on AWS"" posts have left me super confused, so I made this flowchart. It's probably also wrong.",,1622774197.0,939
1,aws,https://i.redd.it/yd8auoi5rza71.png,"Since you all liked the containers one, I made another Probably Wrong Flowchart on AWS database services!",,1626186983.0,759
2,aws,https://www.reddit.com/r/aws/comments/ivwj2w/acloudguru_is_scamming_people_secretly_removed/,Acloudguru is scamming people. Secretly removed Linuxacademy courses and replaced it with their inferior content,"**Acloudguru is scamming people and going back on their promise.**

When Acloudguru took over LinuxAcademy they assured us that we will have access to both catalog of courses. This was a lie.

I paid for Linuxacademy yearly subscription to access their AWS Architect Pro and Devops Pro courses. 

**When I logged in a few days ago I found out that ACG removed 50 hour Aws Architect Pro Linuxacademy course by Adrian Cantrill and replaced it with their ACG inferior 14 hour course by Scott Pelter**

**ACG removed 32 hour Devops Pro course and replaced it with their garbage 6 hour course. In actuality it’s only 4 hours!! Because they sneakily marked each section quiz as 4 hours long and added it to course total.**

This is clearly not what I and other Linuxacademy members paid for. We would like the content that we paid for. Ryan Kroonenburg should be ashamed of himself for scamming people.

I opened a ticket and was told by ACG rep that if I didn’t watch any video from Linuxacademy AWS Pro courses before then I won’t have access to them. Which is completely the opposite of what we were told when ACG took over.

They are slowly replacing all LinuxAcademy courses with shorter, vomit inducing ACG products. 

**Also they sneakily inflate course length by making their quizzes as 4 hour long each. For example there are 6 quiz for AWS Devops Pro exam. So 6 x 4 is 24 hours. The total length of AWS Devops pro course advertised by ACG is 27 hours. So there is only 3 hours of content. No really, go check!**

Linux academy had such great courses and content. Acloudguru is completely destroying all of its credibility and scamming people on top of it. I advise not to get any subscription with them. 

Rather support people like Stephen Maarek, Adrian Cantrill, Eissa Sharif, Neal Davis etc.",1600535539.0,654
3,aws,https://i.redd.it/gqvebjo9hf9b1.jpg,What does he mean by “tech stack is on an AWS S3 cluster”?,,1688249747.0,646
4,aws,https://www.reddit.com/r/aws/comments/9pefq8/aws_support_now_officially_on_reddit/,AWS Support now officially on Reddit!,"Hello /r/aws,

AWS Support has officially landed! 

To better support the thriving community here, we have created an official AWS Support account! We will specialize in **Account & Billing questions** and do our best to resolve your issue, address your feedback, or point you toward resources that can help.

Please bear with us as we get this program off the ground, and let us know how we’re doing and how we can improve your experience with us. Shout out to moderator u/ckilborn for helping us get started!

Thanks for building on AWS!",1539905421.0,618
5,aws,https://www.reddit.com/r/aws/comments/rb1xrd/500502_errors_on_aws_console/,500/502 Errors on AWS Console,"As always their Service Health Dashboard says nothing is wrong.

I'm getting 500/502 errors from two different computers(in different geographical locations), completely different AWS accounts.

Anyone else experiencing issues?

&#x200B;

ETA 11:37 AM ET: SHD has been updated:

>8:22 AM PST We are investigating increased error rates for the AWS Management Console.  
>  
>8:26 AM PST We are experiencing API and console issues in the US-EAST-1 Region. We have identified root cause and we are actively working towards recovery. This issue is affecting the global console landing page, which is also hosted in US-EAST-1. Customers may be able to access region-specific consoles going to [https://console.aws.amazon.com/](https://console.aws.amazon.com/). So, to access the US-WEST-2 console, try [https://us-west-2.console.aws.amazon.com/](https://us-west-2.console.aws.amazon.com/)

ETA: 11:56 AM ET: SHD has an EC2 update and Amazon Connect update:

>8:49 AM PST We are experiencing elevated error rates for EC2 APIs in the US-EAST-1 region. We have identified root cause and we are actively working towards recovery.  
>  
>8:53 AM PST We are experiencing degraded Contact handling by agents in the US-EAST-1 Region.

Lots more errors coming up, so I'm just going to link to the SHD instead of copying the updates.

[https://status.aws.amazon.com/](https://status.aws.amazon.com/)",1638891679.0,556
6,aws,https://www.reddit.com/r/aws/comments/liiki3/aws_support_is_better_than_any_other_vendor/,AWS Support is better than any other vendor support I've used.,"I've been working professionally in IT for a decade in a variety of roles. I've opened tickets with Microsoft, VMware, Novell, Oracle, SolarWinds, Dell, EMC, NetApp, Red Hat, and many more. I've been working full time with AWS for over four years now and their Support has ALWAYS been top notch.

Yesterday's example: We're looking at using the new S3 PrivateLink (Interface Endpoint) functionality and our devs have a use case that uses S3 Presigned URLs. We haven't used them much publicly let alone with PrivateLink, but were able to get a Presigned URL to work and download files via the Interface Endpoint, except we kept getting SSL errors no matter the different approaches we tried due to certificate not matching our vpce- hostname. I confirmed our dev's experiences so I decided to open a ticket to see if AWS had a solution. I opened a chat and talked to someone within 5min, they understood the issue and my goal, they reproduced it themselves while chatting (I assume in their own environment). They did as much internal research as they could but found no solution so escalated to the product team. I feared this would be kicked back as a known limitation. This morning they got back to me with a straightforward answer that you need to make the request to a specific subdomain under endpoint hostname and it worked flawlessly.

Let's review:

* Talked to a person within 5 min of submitting a ticket
* They spoke clear, concise English
* Tried to understand my problem and reproduced it
* Used the tools at their disposal to try to resolve my issue
* Escalated to experts when they could not resolve
* Followed up within 24hrs with a solution including detailed instructions to resolve my issue

When was the last time you got support like that from a big name company? When I was still working with Oracle I wouldn't even bother with their support infrastructure anymore due to bad communication, responding off business hours, slow response times, constantly pushing issue back on customer, and the general vibe that they just want the customer to go away. Others may get you across the finish line, but only after several business days of back-and-forth sending logs and phone calls, webexes, etc.

Anyway, other people probably have had less stellar experiences with AWS Support, but every single time I've interacted with them I just feel more validated that AWS is the right place for us to focus instead of our smaller Azure environment. AWS touts putting the customer first and for me, that shows in everything they do.",1613157846.0,513
7,aws,https://i.redd.it/d6gghoyhyyp81.jpg,Trouble choosing the services (read comment),,1648406391.0,492
8,aws,https://www.reddit.com/r/aws/comments/ii8ts4/the_new_route_53_ui_is_terrible/,The new route 53 UI is terrible,"Didn't I already post this? Oh wait no, I'm sorry. That was the new calculator UI.

AWS...please stop with all the wizard nonsense. Again. I don't need a wizard to hold my hand through creating a TXT record. I need something simple, or as you now call it, the ""old console"". I get the desire to create an experience, but please do it where it is warranted. Who in the community is asking for you to complicate the process of creating DNS records? I would rather you take us back to the days of editing BIND files with VIM than have to work in your new console. And I am not alone! A colleague of mine today just shared his feelings to me about your new console. He said, "" real DNS ballers edit BIND files with vim"". If you need a wizard to create DNS records, you should not be creating DNS records.",1598627567.0,484
9,aws,https://i.redd.it/5jm26apleai71.png,"Fun fact: type ""lamdba"" into your AWS search bar to find all documentation and articles where ""lambda"" is misspelled",,1629366939.0,474
10,aws,https://reinvent.awsevents.com,re:Invent 2020 will be free and virtual!,,1596048947.0,450
11,aws,https://www.reddit.com/r/aws/comments/ecf5i3/were_reddits_infrastructure_team_ask_us_anything/,"We're Reddit's Infrastructure team, ask us anything!","Hello r/aws!

The Reddit Infrastructure team is here to answer your questions about the the underpinnings of the site, how we keep things running, how we develop and deploy, and of course, how we use AWS.

**Edit: We'll try to keep answering some questions here and there until Dec 19 around 10am PDT, but have mostly wrapped up at this point.** Thanks for joining us! We'll see you again next year.

Proof:

[It us](https://preview.redd.it/a52e6qpouf541.jpg?width=4032&format=pjpg&auto=webp&s=45084b3b3e84806bf2f33a68abd91241c33bf27c)

Please leave your questions below. We'll begin responding at 10am PDT.

AMA participants:

u/alienth

u/bsimpson

u/cigwe01

u/cshoesnoo

u/gctaylor

u/gooeyblob

u/kernel0ops

u/ktatkinson

u/manishapme

u/NomDeSnoo

u/pbnjny

u/prakashkut

u/prax1st

u/rram

u/wangofchung

u/asdf

u/neosysadmin

u/gazpachuelo

As a final shameless plug, I'd be remiss if I failed to mention that we are [hiring](https://www.redditinc.com/careers) across numerous functions (technical, business, sales, and more).",1576687912.0,420
12,aws,https://aws.amazon.com/message/11201/,Summary of the Amazon Kinesis Event in the Northern Virginia (US-EAST-1) Region,,1606560339.0,412
13,aws,https://i.redd.it/kdzk8579cjv31.png,I made a chrome extension to color the console header depending on the region. Do you find the idea interesting ?,,1572378919.0,415
14,aws,https://www.reddit.com/r/aws/comments/m77p5g/aws_cognito_amplify_auth_bad_bugged_baffling/,"AWS Cognito & Amplify Auth - Bad, Bugged, Baffling","## What this article is about

I'm going to express my dissatisfaction with **AWS Cognito** and **Amplify Auth**. If you intend to use these services in the future, or you're already using them, you can probably get something out of reading the article, potentially save yourself some hair pulling.

I'll try to be as objective as I can be in my criticism. I don't have a dog in this race. I don't represent anyone. I use these services every day. If some of these bugs are fixed, I'll be a happy camper.

If you want to make edits to the article you could do it by opening an issue or pull request on [github](https://github.com/bobbyhadz/bobbyhadz.com/blob/master/src/blog/aws-cognito-amplify-bad-bugged.md)

## The change email functionality has been bugged for ~ 3 years

It's very common to implement auth with email as a username, unsurprisingly **AWS Cognito** supports this behavior.

[email sign in](https://preview.redd.it/7tb151qxpmn61.png?width=1423&format=png&auto=webp&s=29ff615f4ff21ca98474885a03741ec925fa322c)

You wouldn't want someone to register **with an email they don't own**, it's not secure and enables a **user to reserve emails they don't own** and block the actual email owners. Therefore you would need an email verification step (like every other site on the internet). Cognito also provides this functionality:

[require email verification](https://preview.redd.it/kixran89qmn61.png?width=1351&format=png&auto=webp&s=68250edac8dab249384d37530270b2881d995917)

Ok so what's the problem?

1. The user **requests an email change**, but **doesn't verify the new email** with the **verification code**
2. Cognito automatically updates the email attribute in the user pool, even though it wasn't verified.
3. If the user then logs out, they can only log in with their new - **not verified email**
4. The **new, not verified email** is already taken in the user pool, which blocks any users who might have that email from using your website.
5. The old email the user used is now available, in case someone decides to grab that one.

The expected behavior would be:

## Resolved

1. The user requests an email change
2. The user clicks on the link sent to their new email address
3. AWS Cognito verifies the email and updates the `email` attribute in the user pool

## Rejected

1. The user requests an email change
2. The user doesn't click on the link sent to their email address
3. AWS Cognito does nothing

Why did cognito change my email to `john@gmail.com` if I never verified it?

[change email bug](https://preview.redd.it/g6g3a0chqmn61.png?width=1212&format=png&auto=webp&s=9efdd29a81830387d7dbf5e5f3bcccaa951530ce)

Why am I able to log into my application as `john@gmail.com`?

[logged in as john@gmail.com](https://preview.redd.it/5edaj3jjqmn61.png?width=1285&format=png&auto=webp&s=9c5faa190765f3a069447d083a0fa1fea57899c6)

So I can log in with an email I haven't verified, even though I explicitly selected that I want users to verify their email.

This [issue](https://github.com/aws-amplify/amplify-js/issues/987) has been open for approximately 3 years.

Let's look at the source and see how we would tackle it:

## Default behavior

        if (user.requestsEmailChange()) {
          sendConfirmationEmailToNewEmail();
          updateUserEmailToNewEmail();
        }

## Proposed changes

        if (user.requestsEmailChange()) {
          sendConfirmationEmailToNewEmail();
        }
    
        if (user.hasClickedConfirmationLink()) {
          updateUserEmailToNewEmail();
        }

All I can say is hopefully this gets fixed some day, let's move on.

## The baffling custom email messages default behavior

When a user registers, requests an email change, requests a password reset etc, **we have to send them an email**. The default email cognito sends looks like:

[default email](https://preview.redd.it/nqh4renvqmn61.png?width=525&format=png&auto=webp&s=cd13c05d0793fc1e72f9215f3631927f2c3425bd)

**You would probably want to customize this email**. The way to do this in cognito is to use a `Custom message` lambda trigger.

That's all good, however one day I updated my custom lambda trigger and added a custom html string email template I'd send to my users. **After I made the update** I tested it and **I was still getting the default behavior** with the one liner email of type `The verification code to your new account is 183277`.

So I spent the next 4-5 hours debugging and it turns out the reason for this was that **the maximum length for custom email messages is** `20,000 UTF-8 characters` \- [docs](https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pool-settings-email-verification-message-customization.html).

So the way they decided to handle the case where I send **21,000 UTF-8 characters** is to **ignore my custom message** and **send their default message**, without giving me any indication as to what the cause was.

It's very easy to reach and surpass the limit, especially if you use a templating language to write your emails. So **let's say that for some crazy reason, the limit of 20,000 characters made sense**,

>shouldn't the default behavior be to send you an error indicating the problem?

Instead they send you an email of form: `Your code is 123.`. And you have to debug a custom cognito trigger and figure out:

>Oh, the reason it doesn't work is because I'm sending 21,000 UTF-8 characters and not 19,000, now I understand.

Now I need a custom trigger for my custom trigger to count the UTF-8 characters and alert me if they're more than 20,000, otherwise I'd send a one liner email in production and get fired.

They can **change this behavior to throw an error and inform the developer**, like tomorrow, and the result would be **hundreds of developer hours saved**.

What makes this even more confusing is, **there are actually multiple reasons** as to why **they silently ignore your custom email** template and send the default one:

1. [Having verification type set to link](https://github.com/amazon-archives/amazon-cognito-identity-js/issues/521)
2. [Trying to access event.userName](https://stackoverflow.com/questions/61514305/aws-cognito-custom-email-message-with-lambda-trigger-being-overwritten)
3. [A million of other reasons](https://stackoverflow.com/questions/56865198/how-to-send-a-custom-message-for-custommessage-admincreateuser-trigger)

So many developer hours wasted for no reason, is it that hard to handle the error and inform the developer?

It makes me wonder who is the **target audience of this default behavior**, is it the **end user** or is it **the developer**?

* The **end user** gets a one liner of type `Your code is 123.`, to say that's confusing would be an understatement
* The **developer** implements a custom function with a custom email and gets the default one line email. Now you're **right where you started** but you've wasted a couple of hours.

Let's look at the source:

## Default behavior

        const NICE_ROUND_NUMBER = 20000;
        
        if (email.message.length > NICE_ROUND_NUMBER) {
          return `Your code is ${Math.random().toFixed(4) * 10000}`;
        }

## Proposed changes

        if (email.message.length > NICE_ROUND_NUMBER) {
          throw new Error(
            `For some reason the maximum length of emails is 
            ${NICE_ROUND_NUMBER} and your email is ${email.message.length}
            characters long.`,
          );
        }

This would be another easy fix for Cognito. Anyway let's move on.

## Custom attributes are a MESS

When you want to **store a property on a user** that's **not included in the default provided cognito ones**, you have to use a **custom attribute**, i.e. add a boolean `isAdmin` to your user.

However it's not that simple, because there are huge inconsistencies between the types of custom attributes said to be supported.

1. [Cognito docs](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-settings-attributes.html#user-pool-settings-custom-attributes) and the console say:

* Each custom attribute can be defined as a `string` or a `number`.
* Each custom attribute **cannot be removed or changed once added** to a user pool.

[custom attributes console](https://preview.redd.it/93zwyoymrmn61.png?width=1432&format=png&auto=webp&s=6f45646a0bd1ff2aebd5fc5cbef1c62d1624b1e0)

Okay so I guess custom attributes support only `string` and `number` type and I have to be very careful when picking the type, because **I can't remove / update the custom attribute later**, which means that **the only way would be to delete and recreate my user pool**.

2. [Cloudformation docs](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cognito-userpool-schemaattribute.html#aws-properties-cognito-userpool-schemaattribute-properties) and [CDK docs](https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-cognito.ICustomAttribute.html#interface-icustomattribute)

* Allowed values: `Boolean` | `DateTime` | `Number` | `String`

I guess they just didn't implement the `boolean` and `datetime` types in the console yet, but they are supported by `cloudformation` and `CDK`.

I mean **if they aren't supported I'm gonna get an error** and my **stack will be safely rolled back**, right? Let's try:

        this.userPool = new cognito.UserPool(this, 'userpool', {
          // ... other config
          {
            myBoolean: new cognito.BooleanAttribute({mutable: true}), // 
            myNumber: new cognito.NumberAttribute({mutable: true}), // 
            myDate: new cognito.DateTimeAttribute({mutable: true}), // 
          },
        }

My stack update actually **succeeded**, let's open **the console** and see what happened:

https://preview.redd.it/8rlsom8urmn61.png?width=1409&format=png&auto=webp&s=eda4156e0e3af2e4e7a52489cc529d62b6cd163a

So at this point I'm thinking, **I guess they implemented the other types** as well, they **just didn't update the console interface, right**? Let's log into our application and see if the types are supported.

First we'll try a custom attribute boolean:

        const profileAttributes = {
          'custom:myBoolean': true,
        };
        
        return Auth.updateUserAttributes(user, profileAttributes);

[custom attribute boolean error](https://preview.redd.it/uoqgy5u1smn61.png?width=971&format=png&auto=webp&s=fe1e614dae97ad00c3df878c0137aec9ab37d8e2)

Okay, we get an error: **TRUE\_VALUE can not be converted to a String**, I guess booleans are not supported? I mean **CDK** and **Cloudformation** both **said booleans were supported**, the stack update went through with the boolean value, I guess after all they're not supported, too bad I **can't update/remove this attribute now**.

Let's try with a number, the number type is supported according to **CDK/Cloudformation/Cognito docs/Cognito Console**. There's no way it doesn't work, right?

        const profileAttributes = {
          'custom:myNumber': 42,
        };
        
        return Auth.updateUserAttributes(user, profileAttributes);

[custom attribute number](https://preview.redd.it/1z4crt67smn61.png?width=1013&format=png&auto=webp&s=7630fb27574118bb9ac7daa2483fc5fda6ae6b1d)

So we got an error: **NUMBER\_VALUE can not be converted to a String**.

I can't use a number either? I guess not. But all docs said I could. It turns out the problem is in my code. Look at [this solution](https://github.com/aws-amplify/amplify-js/issues/2958#issuecomment-497348646)

>All I had to do is wrap my number into quotes, like this '42'

[custom attribute number-string](https://preview.redd.it/gll1f7sbsmn61.png?width=938&format=png&auto=webp&s=ad1460fb8c315f5dba73a23276c7d743d6ebf770)

All you have to do is **wrap your number into quotes** \- `'42'`, in other words convert your number to a `string`, so that you can use a `number` type for your custom attributes 

What the `number` type actually means is - they try to parse your `string` input as a `number` and if it fails, it throws an error. You then are responsible to parse the `string` into a `number`, for your conditional checks all throughout your application code.

## Default behavior

>**Cognito docs/console**: Custom attributes can be defined as string or a number  
>  
>**CDK / Cloudformation docs**: Custom attributes can be Boolean, DateTime, Number or String

## Proposed behavior

>Custom attributes are of type **string**. We provide a `number` constraint, which tries to **parse your string input as a number** and if it fails, it throws an error. You are then **responsible to parse the string into a number** for your conditional checks.

At least this time they throw errors and don't silently decide how to handle things.

Anyway, let's move on.

## Amplify Auth's bundle size

So I just finished building a website, and I ran some checks to analyze my bundle size. I was very surprised to see that the bundle size for my `next.js` application was approximately `~400Kb gzipped`. That's huge, I don't that many external libraries so I started investigating.

It turns our `300Kb gzipped` of my `400Kb` were from the module `@aws-amplify/auth`. They were including the same library named `bn.js` like 7 times - [github issue](https://github.com/aws-amplify/amplify-js/issues/7570#issuecomment-767639192)

https://preview.redd.it/8bhttyajwmn61.png?width=1919&format=png&auto=webp&s=8711f471feaa1331d6a7eeaaeed1d22443acc280

Initially I thought that's only 6 instances of `bn.js` being bundled, but **if you look closely**, **there's a cheeky 7th instance in the right top corner** of the node\_modules section.

Well this is a little annoying, but it's being worked on by the amplify team, [thanks, Eric Clemmons](https://github.com/aws-amplify/amplify-js/issues/7570#issuecomment-788405226)!

Update from 17.03.2021, it seems that this issue has been [fixed](https://github.com/aws-amplify/amplify-js/issues/7570#issuecomment-790050205) by the Amplify team! I have not had the chance to try it out yet(it was fixed today), but the issue was closed.

## Unverified emails of users registering with Google / Facebook OAuth

>I'm going to warn you OAuth with Cognito and Amplify is the worst, so if you have to implement it, prepare mentally.

* Everyone who ever implemented OAuth with Cognito and Amplify

You **need your users to have their email verified**, because, otherwise you can't use **Forgot Password** and some other functionality: 

&#x200B;

[reasons to verify emails](https://preview.redd.it/q27wg8eysmn61.png?width=1336&format=png&auto=webp&s=e9bdf8adb9ac3eb9dc06cdfce0c4413410605529)

So on your site you provide a functionality for users to register with **Google** or **Facebook** OAuth. Have you ever seen an implementation where you make the users who sign up with **Google** or **Facebook** confirm their email? No? Ok, that's the first one.

The [default behavior with cognito](https://github.com/aws-amplify/amplify-js/issues/5117#issuecomment-604729707) is:

>Amazon Cognito did state by default they assume that any email/phone number they get from the result of a federated sign up or sign in is not verified so they do not set any values for the attribute for the user. Another note, the returned attribute from the IdP also has to have the value be set to the string ""true"" in order for us to set email\_verified to true

So by default they assume that **facebook and google emails are unverified**. How secure, they don't verify the email of facebook/google users by default, right? But their email change functionality is broken, so it's neither here nor there.

Notice how he also noted that the custom attribute has to be set to the `string` **""true""**, I guess I'm not the only one getting confused about `string-booleans` and `string-numbers`.

In my opinion, if the **user has access to a google/facebook account** with the email `john-smith@gmail.com`, then both accounts - the cognito native and facebook/google should be with **email\_verified set to true**.

Let's look at **how we can verify the email of a user who registered with Facebook and Google**.

>Spoiler alert, it's going to be kind of difficult and **DIFFERENT**, between the different OAuth providers.

## Verify a Google registered user's email

Let's start with **Google**. You would think that the best way to verify a user's email, would be in the `pre-sign-up Lambda` trigger. You check **if the user who's trying to register comes from an external provider Google**, if they do, you know that they're the owner of the email so you set their email verified property to true.

According to the [docs](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-pre-sign-up.html#aws-lambda-triggers-pre-registration-example-2), you can verify the email something like:

        // Set the email as verified if it is in the request
        if (event.request.userAttributes.hasOwnProperty('email')) {
          event.response.autoVerifyEmail = true;
        }

The only problem is that [autoVerifyEmail doesn't work with identity Providers](https://github.com/aws-amplify/amplify-js/issues/5287)

Unlucky, buddy, so close.

Anyways eventually you figure it out, you have to provide an attribute mapping between Google's `email_verified` attribute and cognito's `email_verified` attribute.

        this.identityProviderGoogle = new cognito.UserPoolIdentityProviderGoogle(
          this,
          'userpool-identity-provider-google',
          {
            // ... other config
            attributeMapping: {
              email: {
                attributeName: cognito.ProviderAttribute.GOOGLE_EMAIL.attributeName,
              },
              custom: {
                email_verified: cognito.ProviderAttribute.other('email_verified'),
              },
            },
          },
        );

Problem solved, Google was easy money, let's now look at how we can verify a Facebook email, you kind of assume it would be the same for Facebook right? Well, you assume wrong, because Facebook doesn't have an `email_verified` attribute.

## Verify a Facebook registered user's email

Facebook doesn't keep state of an `email_verified` property. So you try your best, but you don't succeed, you start to look around for solutions on the internet.

Let's look at the [proposed solution from the cognito team](https://github.com/aws-amplify/amplify-js/issues/5117#issuecomment-663011185) for verifying a Facebook registered user's email:

>Amazon Cognito invokes Post Authentication trigger after signing a user, allowing you to add custom logic after authentication. Until the feature is released, you can update ""email\_verified"" attribute using ""AdminUpdateUserAttributes"" API in a Post Authentication trigger which you have already implemented. Please note once the user has sign-up, **this trigger will be executed for every future successful sign-in**.

Needless to say the `""feature""` of automatically verifying Facebook user emails never got released.

When you try to verbalize all this, it starts making sense -

>In order to verify the email of a user who registered with Facebook, you have to add a Post Authentication lambda trigger. The trigger runs every time the facebook user logs in, and verifies their email, now I understand 

You would think this makes no sense, why don't you just use the `Post Confirmation` trigger, which runs only after a user has successfully been registered? Well because you'd get a [race condition](https://github.com/aws-amplify/amplify-js/issues/5117#issuecomment-661546722) leaving your application in a silently broken state.

## Default behavior

>The emails of users who registered with Google / Facebook are not verified by default.

## Proposed behavior

>Flip the boolean folks, please. Ongoing **feature** request for flipping a boolean shouldn't take a year, right?

## Cognito / Amplify OAuth - Linking native to external users

When you provide both OAuth and email registration functionality, a user might register both ways - with their email and with their google account.

So how do you think cognito handles this by default, I mean surely **you wouldn't want to have 2 users in your user pool with the same email**. That **would be very confusing** for the user, they log with their email and add an item to their cart, then they log on their phone with google with the same email, and the item is not in the cart.

As you might have guessed **cognito doesn't handle this at all**, and the **default behavior** is you just have users with the same email that are **not related** to one another.

Can you think of a use case for a **user having 2 accounts with the same email**? No? Ok.

In cognito your **email account** might have attributes X,Y,Z and **Google**, or **Facebook** might not have those attributes on the user object. How would you handle that behavior for your users with 2 separate accounts with the same email in your application.

Let's think about this.

Scenarios 1 and 2:

1. User has already registered with cognito native and now they create a **Google** account, with the same email, we should:

* If there is an email that is equal to the email of the Google OAuth account in the User Pool - `Link those accounts`.
* verify their email, if the user has access to Facebook account with email `john@gmail.com`, then they own that email.

1. User registers with **Google**, we should:

* Create the **Google OAuth** account in the User Pool
* Create a **native cognito user** \- email account
* Link those accounts
* Verify the email

Now you **don't have 2 accounts for the same email** and **can use user attributes** across the different authentication providers - it's a no-brainer. You can **manage** user properties in your app, i.e. **shipping address, city, country, preferences**, etc, that you can't access from their google account. This also allows us to enable reset password functionality, in case the user forgets and tries to log in with their email address, everything just works. Wouldn't it be nice for everything to just work?

>You don't use a managed auth service to have to implement everything yourself. Why is the default behavior to always delegate to the developer.

The only good reason I can think of to not have your accounts with the same email linked by default is if you don't trust the identity provider requires email validation, that's their excuse - security. If the Identity Provider doesn't require email validation, then I could register with an email I don't own - i.e. [**bob@gmail.com**](mailto:bob@gmail.com) , I would come register in your application and steal bob's account, because I got linked to it automatically. Well **fortunately for us**, **both Google and Facebook require email validation**, so I'm leaning more towards the cognito team just couldn't bother.

## Default behavior:

>You have 3 SEPARATE, UNRELATED accounts with the email [bob@gmail.com](mailto:bob@gmail.com) \- a native cognito account, a Facebook account and a Google account.

## Proposed behavior:

>If a user registered with Google and they have a Cognito email account - link those accounts.  
>  
>If a user registered with Google and they don't have an email account, create the google account, create an email account and link those accounts.

I'm not going to get into how they handle email change functionality for linked accounts, we saw that they don't handle it for isolated email registered accounts, so I don't feel like beating a dead horse, if you have to implement it - unlucky buddy.

## OAuth registration with Amplify

The first time a user registers with an OAUTH provider they get an error:

[oauth registration error](https://preview.redd.it/u0ktxfg9umn61.png?width=1546&format=png&auto=webp&s=9de1befd2ff30c7be9bd6444b6d638c94983cb85)

Error: **Error handling auth response. Error: Already+found+an+entry+for+username+Google\_...**

You start looking for a solution and you see some of the issues and hundreds of the developer hours lost:

1. [Cognito Auth fails with ""Already found an entry for username""](https://stackoverflow.com/questions/47815161/cognito-auth-flow-fails-with-already-found-an-entry-for-username-facebook-10155)
2. [Integrate facebook/google login to userpool](https://github.com/aws-amplify/amplify-js/issues/5036)
3. [Unable to log in first-time Cognito User Pool users after a recent change](https://forums.aws.amazon.com/thread.jspa?threadID=267154)

And then you see the AWS Employee (it's in link number 3):

&#x200B;

[their plans](https://preview.redd.it/9dkye6fhxmn61.png?width=768&format=png&auto=webp&s=0a5aa32972835be49ed912fc07340a13187ae8fe)

>Our plans are to provide built-in support for linking between ""native"" accounts and external identities such as Facebook and Google when the email address matches.  
>  
>We do not provide timelines for roadmap items, but I will tell you this is an area under active development.

**3 years** later this feature still hasn't been added.

Legend has it this feature is still under active development, same as the change email bug fix. Can't give you a timeline right now, but know that if it takes this long it's gonna be good 

Anyway, the way to handle this error is to catch it on your redirect route, i.e. your `/` route and handle the error, by starting the OAuth flow again, and opening the OAuth window:

        const Home: React.FC = () => {
          const router = useRouter();
          useEffect(() => {
            if (
              router.query.error_description &&
              /already.found.an.entry.for.username.google/gi.test(
                router.query.error_description.toString(),
              )
            ) {
              handleGoogleLogin();
            } else if (
              router.query.error_description &&
              /already.found.an.entry.for.username.facebook/gi.test(
                router.query.error_description.toString(),
              )
            ) {
              handleFacebookLogin();
            }
          }, [router.isReady, router.query.error, router.query.error_description]);
        
          // rest...
        };

Hopefully they don't change their error messages because my brittle code would break instantly, unlucky buddy.

## All the small things - Amplify's error throwing

Speaking of error messages, **Amplify throws all kinds of error types** and signatures which is very unfortunate, because you have to catch these errors.

* Sometimes they `Promise.reject` with a string, like in their `currentAuthenticatedUser` method:

[current authenticated user error](https://preview.redd.it/26yc1fdpumn61.png?width=605&format=png&auto=webp&s=b3c8d4cfad9738e2f9c037180adf1288d328d5cc)

* Sometimes they throw an **object** that is not instance of `Error` (Error is a function type in JS), like in their `updateUserAttributes` method:

[update user attributes error](https://preview.redd.it/1wa2psfsumn61.png?width=1028&format=png&auto=webp&s=5297c3bc56fdbcba2e5bf6018f80b9a1b07bf431)

* Most of the time they throw an instance of `Error`

I try so hard to catch them all, but in the end I have to read their source code.

You kind of **expect to get an error** of the **same type** from the same package. Otherwise **you have to check for everything** all the time. They throw instances of Error 95% of the time and the just randomly sprinkle misc error types here and there.

## Default behavior:

>They throw various types of errors which bloats your catch block and leads to unhandled errors and bugs

## Proposed behavior:

>Please, just throw the same error type consistently

## The random unexplained errors

These are the errors you get and you can't reason about, because they make no sense whatsoever, you look at the clock, 5 hours have passed, you've made 0 progress, you're sweating profusely and have had too much coffee, now you won't be able to sleep and you'll have to think about cognito and amplify the whole night.

I'm only going to include 1 of these errors, because they kind of are all the same, not very interesting, once you encounter them you start googling around, if you find something - nice, if you don't - unlucky buddy.

When you have users register with OAuth providers, you can enable attribute mappings. I.e. the Google account `first_name` attribute to be mapped to Cognito's `first_name` attribute.

There's this attribute `preferred_username`, and when you map it using Google as OAuth provider, it works:

        this.identityProviderGoogle = new cognito.UserPoolIdentityProviderGoogle(
          this,
          'userpool-identity-provider-google',
          {
            // other stuff..
            attributeMapping: {
              preferredUsername: {attributeName: 'email'},
            },
          },
        );

The same attribute mapping, but for Facebook:

        this.identityProviderFacebook = new cognito.UserPoolIdentityProviderFacebook(
          this,
          'userpool-identity-provider-facebook',
          {
            // ... other stuff
            attributeMapping: {
              preferredUsername: cognito.ProviderAttribute.FACEBOOK_EMAIL,
            },
          },
        );

The only problem is you can't use the facebook mapping, it's bugged and causes an error:

[preferred username error](https://preview.redd.it/7kkyjw50vmn61.png?width=1027&format=png&auto=webp&s=02bfe54517eb74826188fc432294a7791669c135)

Error: errordescription=attributes+required&error=invalid\_request

I would have preferred, if the `preffered_username` attribute mapping didn't throw a **cryptic error** for no reason, but it is what it is, five hours later I figured it out.

There are other causes for this error as well, so best believe the select few that encounter it are in for a treat.

## End

Believe it or not there are other things I didn't include in this post, but no one is probably going to read the whole thing so I won't bother.

I use a **MANAGED** auth service to boost my productivity, well it's NOT working. Spending hours and hours debugging / implementing common sense ""features"" that should be the default behavior doesn't boost your productivity very much.

My **intent with this article is not to mock/offend anyone**. My **goal is to hopefully see some of these problems fixed** in the future. If these teams are understaffed, hopefully they get money to hire more people. I've spent hundreds of hours learning these services, so if I were to cut my losses, these are some significant losses I'd have to cut.

I've tried to be as objective as possible, **I don't work for a competitor**, I don't have a dog in this race, if cognito and amplify improve - my development experience improves.

If I've misunderstood/misrepresented something it was not intentional and if you correct me, I'll update the article.

If you made it this far, pat yourself on the back, hopefully you're more prepared when you encounter one of these issues. **Thank you for reading!**

Also how has your experience been with **Cognito** and **Amplify**?",1616007318.0,408
15,aws,https://www.reddit.com/r/aws/comments/rvi9a8/thanks_to_all_of_the_my_account_was_hacked_posts/,"Thanks to all of the ""My account was hacked!"" posts here, I finally setup MFA on all of my accounts","Just wanted to post a thank-you for all the hard lessons learned by the community. 

It was the final motivation I needed to setup MFA across all of my environments in all of my projects. 

I've been delaying the setup for months. Thanks for the motivation!

Hopefully this serves as a reminder to anyone else viewing this sub to setup MFA!!",1641260855.0,404
16,aws,https://www.teamblind.com/blog/index.php/2021/12/09/why-new-hires-make-more-money-existing-employees/,"A software engineer at Amazon had their total comp increased to $180,000 after earning a promotion to SDE-II. But instead of celebrating, the coder was dismayed to find someone hired in the same role, which might require as few as 2 or 3 YOE, can earn as much as $300,000.",,1639162979.0,391
17,aws,https://aws.amazon.com/certification/faqs/,Covid-19 AWS Certification Update: You can now take all AWS Certification exams with online proctoring,,1584996061.0,389
18,aws,https://www.reddit.com/r/aws/comments/mlfbcw/i_built_a_tool_which_automatically_suggests/,I built a tool which automatically suggests least-privilege IAM policies,"I'm building iam-zero, a tool which detects IAM issues and suggests least-privilege policies.

It uses an instrumentation layer to capture AWS API calls made in `botocore` and other AWS SDKs (including the official CLI) and send alerts to a collector - similar to how Sentry, Rollbar, etc capture errors in web applications. The collector has a mapping engine to interpret the API call and suggest one or more policies to resolve the issue.

I've worked with a few companies using AWS as a consultant. Most of them, especially smaller teams and startups, have overly permissive IAM policies in place for their developers, infrastructure deployment roles, and/or services.

I think this is because crafting truly least-privilege IAM policies takes a lot of time with a slow feedback loop. Trying to use CloudTrail [like the AWS docs suggest](https://aws.amazon.com/premiumsupport/knowledge-center/troubleshoot-iam-permission-errors/) to debug IAM means you have to wait up to 15 minutes just to see your API calls come through (not to mention the suggestion of deploying Athena or running a fairly complex CLI query). Services like IAM Access Analyser are good but they are not very specific and also take up to 30 minutes to analyse a policy. I am used to developing web applications where an error will be displayed in development immediately if I have misconfigured something - so I wondered, what if building IAM policies had a similar fast feedback loop?

The tool is in a similar space to [iamlive](https://github.com/iann0036/iamlive), [policy\_sentry](https://github.com/salesforce/policy_sentry/), and [consoleme](https://github.com/Netflix/consoleme) (all of which are worth checking out too if you're interested in making AWS security easier) but the main points of difference I see are:

* iam-zero can run transparently on any or all of your roles just by swapping your AWS SDK import to the iam-zero instrumented version or using the instrumented CLI
* iam-zero can run continuously as a service (deployed into a isolated AWS account in an organization behind an SSO proxy) and could send notifications through Slack, email etc
* iam-zero uses TLS to dispatch events and doesn't include any session tokens in the dispatched event ([AWS Client Side Monitoring](https://summitroute.com/blog/2020/05/25/client_side_monitoring/), which iamlive utilises, includes authentication header details in the event - however iamlive is awesome for local policy development)

My vision for the tool is that it can be used to give users or services zero permissions as a baseline, and then allow an IAM administrator quickly review and grant them as a service is being built. Or even better, allowing infrastructure deployment like Terraform to start with zero-permissions roles, running a single deployment, and send your account security team a Slack message with a suggested least permissions role + a 2FA prompt for a role to deploy the infrastructure stack.

iam-zero is currently pre-alpha but I am hoping to get it to a stage where it could be released as open source. If you'd be interested in testing it or you're having trouble scaling IAM policy management, I'd love to hear from you via comment or DM. Any feedback is welcome too.

Live demo: [https://www.loom.com/share/cfcb5c20ede94f3d9214abbd28fa7921](https://www.loom.com/share/cfcb5c20ede94f3d9214abbd28fa7921)

https://preview.redd.it/yx5lzel0ekr61.png?width=2676&format=png&auto=webp&s=90294cc62267d9ddd3604f347d02fe54c2d9a38b",1617725763.0,373
19,aws,https://www.businessinsider.com/leaked-document-amazon-salaries-job-offer-715400-2021-8,"A leaked Amazon document shows the maximum compensation a recruiter is allowed to offer some programmer job candidates, up to $715,400",,1629934735.0,367
20,aws,https://www.reddit.com/r/aws/comments/q0m97j/what_wonderful_times_we_live_in/,What Wonderful Times We Live In,"Caveat - not a technical post or question so much as a sort of love letter to the Cloud.

I'm 57 years old and I've been working in the data space for the last 25 years. My first database build was a tactical database in 1990 in dBase III when I was in the Air Force. From there I graduated to Sybase and then to SQL Server. Along the way I've picked up everything from Oracle to SQLite to MongoDB.

This weekend I'm working on a project that involves processing a 10GB json file and databasing it. If I had tried to do this on my MacBook, my laptop would have laughed at me, before it died. Instead, I put in a spot request  on AWS and ended up completing the project in about an hour for about $1.10.

To the folks who've grown up in a cloud first world, this might not seem like a big deal. But even having worked in AWS for five years now, this to me still feels a bit miraculous. Twenty five years ago, if you wanted to say, learn how to build a Linux cluster, you'd buy a book (a very large, heavy book which invariably cost $70) and plow your way through it. And, of course, it didn't do you much good unless you had access to the hardware (and software) to practice on. Learning an other than open source language meant, again, the obligatory doorstop tome and shelling out shekels for an SDK.

In 2021, an afternoon of youtube and some AWS cloud, storage and compute is enough to become well versed in a new skill.  This old dog learns new tricks every day....to me thats still miraculous.",1633281649.0,367
21,aws,https://www.reddit.com/r/aws/comments/h09wl5/dear_aws_stop_ruining_the_freaking_console_ui_rant/,"Dear AWS, stop ruining the freaking console UI [rant]","*I need to get this off my chest, and since this is one of the few places online where people that might share my view on this might see it, I figured it's a good place to go off.*

*If someone from AWS is actually reading this, please pay special attention to the last bit on accessibility, because I'm pretty sure most of the frustration is due to that.*

Dear AWS, please STOP ruining the console UI! I'm not the kind of person that hates change just cause I'm stubborn. If you were improving it, power to ya, but you're not. You are busy making the experience worse. I guess I should thank you because I've been telling coworkers for years to use the CLI and that it's better, and now you are going out of your way to prove my point and drive people there. But sometimes it's just simpler to view a dashboard or play around with a new service using the console. Well, it used to be.

Your transition over to the new UI aren't even smooth on some services. Take EC2 for instance. You rolled out the new look for the Autoscaling section, but most of the time when I navigate there I get the old UI with an error message. When I reload the page, the new UI loads and I can see my resources. Next, CloudWatch Logs. WHY THE HECK WOULD YOU MAKE IT LESS USER-FRIENDLY!? Usually you go to view logs when stuff is broken, often production systems, which is stressful enough. Now you've gone and changed the UI and made it worse. Something as stupid as switching between viewing logs as ""Text"" vs ""Row"" is now in a sub menu in a drop down, why?

That leads me to my next point, sub menus and drop downs. Everything is in a collapsible element. That's freaking annoying. Sometimes you want to copy some text to share with a colleague, but as soon as you click to highlight, the blooming thing expands or retracts  and moves the element. Ultimately you can do what you want to do, yes, but it takes longer. In high paced, high pressure environments, crap like that is something no one needs.

It's one thing to make something look better, but most people that uses AWS don't care about looks. We want functionality and ease of use. It can look like a dog's breakfast for all we care, it just has to work!!

**Accessibility**

As I said at the start, I'm sure most of my frustrations is because you are making the UI less user-friendly for people with vision problems. You are making it harder for me to do my job, and I really don't need anyone to do that.

The old UI was basic, simple, and it was really clear where one section ended and another started. There was less collapsable elements and hidden menus. Yes, sometimes you had to scroll till your fingers went numb, but at least it didn't require clicking on 4 different little arrows and two sub-menus to get to the info you want.

I highlight text that I want my screen reader to read out loud. But it feels like 70% of the time I try that technique with the new UI it doesn't work. The text is either some kind of link or action button that opens a collapsable element, or the reader doesn't pick it up as text. Now I know the first response to that last one will be ""maybe your screen reader is the issue."" But why then is it only on your website? I don't know what kind of UI framework you use, but it's not very accessibility-friendly. It's pretty much impossible to read text in a table. It either doesn't read, or it reads the entire table, no matter which cell I'm highlighting. The worst part is that you're now using this same thing for your documentation pages. I'm basically losing my mind cause I can't read the freaking docs!

Then there is the moving of buttons and options and inconsistent UI's. I'm not talking about the UI being inconsistent across services, it's always been like that. That's something I learned to love about the old UI. I'm talking about something like the Lambda console. Select a function and navigate to the ""Configuration"" tab. All the config sections are full screen-width blocks, except the X-Ray one. In addition to the screen reader, I use a screen zoom function. So I don't see the whole screen. So I basically scrolled up and down and up and down in search of the X-Ray section, thinking I'm not seeing it. Only to find out, nope, that one config block is sitting on the right side of the page, outside the view of the zoom. Again, you could say that's not your problem, but it kinda is. If all the configs were side-by-side, I would be hovering left to right all the way down the page.

The moving of buttons is one of those things that make me want to scream. With the old UI, most of the action buttons is on the left hand side at the top. Now you moved it to the right, but not on all pages. Why? Why would you move something just for the sake of moving it? ""It looks better there."", no it doesn't. It looks the same, it's just orange instead of blue and on the right instead of the left. Most people don't know this, but people with vision problems don't read all the menus/buttons. They memorize button names, link text, and the placement of it to speed up their workflow. Now I basically have to start over.

And finally let's get to colors, fonts, and shadows. The old UI, again, was basic. Black text on a white page, when highlighted it was substantially bolder, and when on a button it was Bol white text on a dark blue background. Here and there there was a menu with white text on black backgrounds. Now everything is a much more modern font, which is thinner and harder to read when highlighted since it doesn't get much bolder. Some pages have colors that are so light that's impossible to see white text, and pages are so busy to cram all the info into a single view, that everything just feels cramped and the font feels smaller.

I can go on, but I'd be pretty surprised if anyone made it this far. I also feel a bit better now, even though as soon as I navigate away from here I'm going back to the console and that kinda sucks.

As I said, I'm not a person that hates change. You updated the Support Center to have the new UI, and apart from the fact that I can't use my screen reader to read the table with all the open cases, it's nice. There's not much wrong with that page and you did a good job there. It's still user-friendly, even for me. Yeah the font/color issue is there too, but other than that.

I'm not the kind of person to just bitch and moan about something and not do something about it. This rant must sound like me bitching and moaning, and honestly, if I was allowed to use all the cuss words that came to mind, it probably would sound more like a rant. But I am willing to help wherever I can to help you improve the console experience. If I have to submit all my suggestions or take screen recordings to explain my situation, I'd gladly do that. I'm just not going to do it if it's going to get ignored. Rather ignore this then.

PS: It's not just AWS that's making this mistake. Even the folks here at Reddit made that mistake with their new look. It's impossible for me to use with my assistive technologies, so I'm still using the old UI. Yeah it looks like something that was created 20 years ago, but it works, and that's what matters.",1591792206.0,364
22,aws,https://www.reddit.com/r/aws/comments/d0hlt0/every_aws_customer_ever/,Every AWS customer ever. . .,"Day 1

""We're not going to rely on AWS specific features.""
  

3 months later
  

""OK, we need to use SQS, Lambda, ECS and DynamoDB but that's it!""
  

6 months later

""OK, we're an AWS shop.""",1567781127.0,360
23,aws,https://aws.amazon.com/service-terms/,AWS taking zombie apocalypse seriously in T&Cs Clause 42.10,,1613657779.0,353
24,aws,https://www.reddit.com/r/aws/comments/148mwol/useast1_down_for_anybody_else/,US-East-1 down for anybody else?,"502s on the console, lambdas not getting resources.

Uh oh",1686682976.0,350
25,aws,https://www.reddit.com/r/aws/comments/1aflm3n/aws_is_estimated_to_make_400_million_to_1_billion/,AWS is estimated to make $400 Million to $1 Billion with the new IPv4 charge,"Tomorrow, the AWS IPv4 rental charge will kick in at $43 per year per IP.  According to this article, it is estimated this new charge will make AWS $400M to 1$ billion a year!  
Other interesting observations:

* Amazon owns 132M ipv4 addresses 
* Worth about 4,6Billion $
* Tomorrow, the AWS IPv4 rental charge will kick in at $43 per year per IP.  According to this article, this new charge is estimated to make AWS $400M to 1$ billion a year!  
Other interesting observations.

More Details: [https://www.border0.com/blogs/ipv4-surcharge---your-aws-bill-is-going-up-this-february](https://www.border0.com/blogs/ipv4-surcharge---your-aws-bill-is-going-up-this-february) 

  
",1706718001.0,346
26,aws,https://www.reddit.com/r/aws/comments/qvm23y/hidden_aws_console_dark_mode/,Hidden AWS Console Dark Mode,"Hello fine folks, I found a little gem in the aws console cookie. Navigate to [console.aws.amazon.com](https://console.aws.amazon.com), open the chrome dev console, and navigate to the Application -> Cookies section. You should see an  entry for ""awsc-color-theme"", default value being ""light"". Just change this to ""dark"" and refresh!

https://preview.redd.it/alucgdj5t1081.png?width=853&format=png&auto=webp&s=49028e4c47a12f82b5be954f38dcc4ddfd20975b",1637107735.0,343
27,aws,https://www.reddit.com/r/aws/comments/ya0bl3/dark_mode_console_has_finally_arrived/,Dark Mode Console has finally arrived,"Announcement:  [https://aws.amazon.com/about-aws/whats-new/2022/10/dark-mode-support-aws-management-console/](https://aws.amazon.com/about-aws/whats-new/2022/10/dark-mode-support-aws-management-console/)

Looks pretty good too, just tried it out",1666375508.0,346
28,aws,https://aws.amazon.com/blogs/aws/announcing-aws-lambda-function-urls-built-in-https-endpoints-for-single-function-microservices/,Announcing AWS Lambda Function URLs: Built-in HTTPS Endpoints for Single-Function Microservices,,1649280208.0,346
29,aws,https://www.reddit.com/r/aws/comments/5wphqj/amazon_s3_and_amazon_ses_are_down/,Amazon S3 and Amazon SES are down,"As of 17:40 UTC, verified on us-east-1. Lots of people affected. Posting here in case anyone's wondering. Reports of EBS being down as well.

Update 17:52 UTC from amazon: 

>We are investigating increased error rates in the US-EAST-1 Region.

Update 18:16 UTC from amazon: 

> We've identified the issue as high error rates with S3 in US-EAST-1, which is also impacting applications and services dependent on S3. We are actively working on remediating the issue.

Update 18:33 UTC from amazon:

> We're continuing to work to remediate the availability issues for Amazon S3 in US-EAST-1. AWS services and customer applications depending on S3 will continue to experience high error rates as we are actively working to remediate the errors in Amazon S3.

Update 19:35 UTC from amazon:

> We have now repaired the ability to update the service health dashboard. The service updates are below. We continue to experience high error rates with S3 in US-EAST-1, which is impacting various AWS services. We are working hard at repairing S3, believe we understand root cause, and are working on implementing what we believe will remediate the issue.

Update 20:41 UTC: I'm starting to see services coming back online. 

Update 21:12 UTC from amazon:

> S3 object retrieval, listing and deletion are fully recovered now. We are still working to recover normal operations for adding new objects to S3.

Update 21:39 UTC: I'm starting to see PUTs coming back online.

Update 22:00 UTC: Most PUTs look like they are back online for me.

Update 22:08 UTC from amazon: 
> As of 1:49 PM PST, we are fully recovered for operations for adding new objects in S3, which was our last operation showing a high error rate. The Amazon S3 service is operating normally.

https://status.aws.amazon.com/

~~Edit: I just want to say, that status page is stupidly useless. Green checkmarks all the way in the middle of all of us-east-1 being down and the console being inaccessible.~~

Edit 2: RED checkmarks on the status page. This is a historic moment.",1488304453.0,335
30,aws,https://www.reddit.com/r/aws/comments/rocp33/mods_can_we_get_a_sticky_post_telling_anyone_that/,Mods: Can we get a sticky post telling anyone that visits this sub to setup MFA/lock down root creds/setup billling alerts/etc.?,"As per the title.  Everyday I step into this sub and see a post about someone getting ""hacked"".  Until AWS makes this default, at least newcomers can be reminded when they visit.",1640449752.0,333
31,aws,https://www.reddit.com/r/aws/comments/ec1t04/fyi_in_the_spirit_of_transparency_stepping_down/,"FYI - In the spirit of transparency, stepping down as a mod","Happy and sad news. 

It's been fantastic to see this sub grow and thrive over the last few years; growing from 25k members to over 100k! I've learned a ton and had some great experiences. However I've recently taken a job at AWS and this makes me feel conflicted about staying on as a mod in this community. Its hard to leave but I feel that mod duties like approving posts/comments, tagging posts, organizing events, etc should ultimately be handled by the community to remove any suspicion of bias.

Please reach out to [**u/Pi31415926**](https://www.reddit.com/user/Pi31415926/) if you would like to help out. See you in the clouds!",1576616051.0,335
32,aws,https://www.reddit.com/r/aws/comments/847imw/soby_popular_demandyou_can_now_make_pull_requests/,So...by popular demand...you can now make pull requests against AWS documentation on GitHub,The AWS docs are now open source! [Jeff Barr’s blog post](https://aws.amazon.com/blogs/aws/aws-documentation-is-now-open-source-and-on-github/) has all the info on how to contribute. Each AWS service guide has its own repo in the [AWS docs organization](https://github.com/awsdocs) on GitHub. You can file issues if you have questions or submit pull requests if you have ideas to help improve the docs. You can watch a repo to monitor changes to those docs or for new feature updates to the service itself. Let us know if you have any questions!,1520973925.0,325
33,aws,https://www.reddit.com/r/aws/comments/rp80z9/when_aws_says_that_the_amazon_linux_kernel_is/,"When AWS says that the Amazon Linux kernel is optimized for EC2, they're not kidding","Just thought I'd share an interesting result from something I'm working on right now.

Task: Run ImageMagick in parallel (restrict each instance of ImageMagick to one thread and run many of them at once) to do a set of transformations (resizing, watermarking, compression quality adjustment, etc) for online publishing on large (20k - 60k per task) quantities of jpeg files.

This is a very CPU-bound process.

After porting the Windows orchestration program that does this to run on Linux, I did some speed testing on c5ad.16xlarge EC2 instances with 64 processing threads and a representative input set (with I/O to a local NVME SSD).

Speed on Windows Server 2019: ~70,000 images per hour

Speed on Ubuntu 20.04: ~30,000 images per hour

Speed on Amazon Linux 2: ~180,000 images per hour

I'm not a Linux kernel guy and I have no idea exactly what AWS has done here (it must have something to do with thread context switching) but, holy crap.

Of course, this all comes with a bunch of pains in the ass due to Amazon Linux not having the same package availability, having to build things from source by hand, etc. Ubuntu's generally a lot easier to get workloads up and running on. But for this project, clearly, that extra setup work is worth it.

Much later edit: I never got around to properly testing all of the isolated components that could've affected this, but as per discussion in the thread, it seems clear that the actual source of the huge difference was different ImageMagick builds with different options in the distro packages. Pure CPU speed differences for parallel processing tests on the same hardware (tested using threads running https://gmplib.org/pi-with-gmp) *were* observable with Ubuntu vs Amazon Linux when I tested, but Amazon Linux was only ~4% faster.",1640559258.0,328
34,aws,https://www.amazon.com/s?i=courses&rh=p_27%3AAWS+Training+%26+Certification&fbclid=IwAR1DccV2NwGhHLjXyqGrptmxECyAQFM2rFoDhO9z_H6kvZV_FviITsBzr_Q&ref=nav_ya_signin,Amazon AWS Certifications Courses Worth Thousands of Dollars are available FREE on Amazon Store.,,1667384219.0,311
35,aws,https://reinvent.awsevents.com/health-measures/,AWS is now requiring all attendees to re:invent to show proof that they're fully vaccinated and wear masks when not eating or drinking,,1631034447.0,307
36,aws,https://aws.amazon.com/blogs/developer/mocking-modular-aws-sdk-for-javascript-v3-in-unit-tests/,"When AWS SDK for JS v3 came out, I created a mocking library for it. Now it's officially recommended by the AWS JS SDK team and my post was published on the AWS blog!",,1627498433.0,302
37,aws,https://www.datacenterdynamics.com/en/news/aws-us-east-1-outage-brings-down-services-around-the-world/,AWS us-east-1 outage brings down services around the world,,1638897615.0,300
38,aws,https://aws.amazon.com/blogs/aws/new-use-mac-instances-to-build-test-macos-ios-ipados-tvos-and-watchos-apps/,EC2 Mac Instances,,1606796961.0,303
39,aws,https://github.com/SkullTech/aws-solutions-architect-associate-notes,"I passed the AWS solutions architect exam about an year ago, wanted to share my journey and my notes. It has already helped a lot of people, hope it also helps some of you.",,1600614506.0,302
40,aws,https://github.com/SkullTech/aws-solutions-architect-associate-notes,"Just passed the AWS solutions architect exam, here are my notes. Hope this helps some of you.",,1564670598.0,304
41,aws,https://www.reddit.com/r/aws/comments/hbztrc/i_wrote_a_free_app_for_sketching_cloud/,I wrote a free app for sketching cloud architecture diagrams,"I wrote a free app for sketching cloud architecture diagrams. All AWS, Azure, GCP, Kubernetes, Alibaba Cloud, Oracle Cloud icons and more are preloaded in the app. Hope the community finds it useful: [cloudskew.com](https://www.cloudskew.com/)

Notes:

1. The app's just a simple diagram editor, it doesn't need access to any AWS, Azure, GCP accounts.
2. You can see some sample diagrams [here](https://www.cloudskew.com/docs/samples.html).

[CloudSkew - Free AWS, Azure, GCP, Kubernetes diagram tool](https://preview.redd.it/9jm111zn1v551.png?width=1438&format=png&auto=webp&s=c33c6eb8c76a0c52408e0c672d36b6eac62a3fed)",1592569770.0,298
42,aws,https://www.businessinsider.com/amazon-managers-performance-reviews-hire-to-fire-internal-turnover-goal-2021-5,Why you should never work for Amazon itself: Some Amazon managers say they 'hire to fire' people just to meet the internal turnover goal every year,,1620832311.0,288
43,aws,https://nathanpeck.com/speeding-up-amazon-ecs-container-deployments/,ECS Container Deployments: Hands down the absolute best article I've found to explain ECS deployments. I wish more people read this article!,,1609775549.0,283
44,aws,https://i.redd.it/wbsltrzefuq91.png,Dear AWS: Please open a US Central Region,,1664477130.0,281
45,aws,https://www.zdnet.com/article/aws-said-it-mitigated-a-2-3-tbps-ddos-attack-the-largest-ever/,"AWS said it mitigated a 2.3 Tbps DDoS attack, the largest ever",,1592410151.0,281
46,aws,https://www.cnbc.com/2023/04/26/amazon-starts-layoffs-impacting-hr-and-aws-cloud-unit.html,AWS Layoffs Take Effect,,1682599330.0,273
47,aws,https://slack.engineering/slacks-outage-on-january-4th-2021/,Slack’s Outage on January 4th 2021,,1612191861.0,274
48,aws,https://www.reddit.com/r/aws/comments/rh1rw7/another_aws_outage/,Another AWS outage?,Unable to access any of our resources in us-west-2 across multiple accounts at the moment,1639582544.0,273
49,aws,https://www.reddit.com/r/aws/comments/ekyj1a/please_use_the_right_tool_for_each_job_serverless/,Please use the right tool for each job - serverless is NOT the right answer for each job,"I'm a serverless expert and I can tell you that serverless is really really useful but for about 50% of use cases that I see on a daily basis. I had to get on calls and tell customers to re-architect their workloads to use containers, specifically fargate, because serverless was simply not an option with their requirements.

Traceability, storage size, longitivity of the running function, WebRTC, and a whole bunch of other nuances simply make serverless unfeasible for a lot of workloads.

Don't buy into the hype - do your research and you'll sleep better at night.

**Update:** by serverless I mean lambda specifically. Usually when you want to mention DynamoDB, S3, or any other service that doesn't require you to manage the underlying infrastructure we would refer to them as managed services rather than serverless.

**Update 2:** Some of you asked when I wouldn't use Lambda. Here's a short list. Remember that each workload is different so this should be used as a guide rather than as an edict.

1. Extremely low-latency workloads. (e.g. AdTech where things needs to be computed in 100ms or less).
2. Workloads that are sensitive to cold-starts. No matter whether you use provisioned capacity or not, you will feel the pain of a cold-start. Java and .NET are of prime concern here. It takes seconds for them to cold-start. If your customer clicks a button on a website and has to wait 5 seconds for something to happen you'll lose that customer in a heartbeat.
3. Lambda functions that open connection pools. Not only does this step add additional time to the cold-start, but there's not clean way of closing those connections since Lambda doesn't provide 'onShutdown' hooks.
4. Workloads that are constantly processing data, non-stop. Do your cost calculations. You will notices that Lambda functions will become extremely expensive if you have a 100 of them running at the same time, non-stop, 100% of the time. Those 100 Lambda functions could be replaced with one Fargate container. Don't forget that one instance of a Lambda function can process only 1 request at a time.
5. Long-running processes.
6. Workloads that require websockets. There's just too many complexities when it comes to websockets, you add a lot more if you use Lambdas that are short-lived. People have done it, but I wouldn't suggest it.
7. Workloads that require a lot of storage (e.g. they consistently download and upload data). You will run out of storage, and it's painful.",1578337351.0,275
50,aws,https://www.lastweekinaws.com/blog/an-aws-bill-analysis-changelogs-md/,"I publicly tore an AWS engineer's AWS bill apart to find savings, then shared the story with the world.",,1583959593.0,268
51,aws,https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_version.html,"Happy 10 year birthday to the current IAM policy language version (""Version"": ""2012-10-17"")",,1666028906.0,264
52,aws,https://dangoldin.com/2020/12/11/amazon-owns-more-than-2b-worth-of-ipv4-addresses/,Amazon owns more than $2B worth of IPV4 addresses,,1607790776.0,267
53,aws,https://diagrams.mingrammer.com/docs/getting-started/examples,Diagrams as code (Python) with AWS icon support,,1589498270.0,263
54,aws,https://github.com/onramper/action-deploy-aws-static-site,I built a GitHub Action that deploys static sites to Cloudfront,,1602543490.0,263
55,aws,https://m.economictimes.com/tech/technology/amazon-to-lay-off-9000-more-workers/amp_articleshow/98821965.cms,"Amazon is laying off another 9,000 employees across AWS, Twitch, advertising",,1679358615.0,257
0,aws,https://i.redd.it/xnblsjm6v5371.png,"The recent ""all the ways to run containers on AWS"" posts have left me super confused, so I made this flowchart. It's probably also wrong.",,1622774197.0,940
1,aws,https://i.redd.it/yd8auoi5rza71.png,"Since you all liked the containers one, I made another Probably Wrong Flowchart on AWS database services!",,1626186983.0,762
2,aws,https://www.reddit.com/r/aws/comments/ivwj2w/acloudguru_is_scamming_people_secretly_removed/,Acloudguru is scamming people. Secretly removed Linuxacademy courses and replaced it with their inferior content,"**Acloudguru is scamming people and going back on their promise.**

When Acloudguru took over LinuxAcademy they assured us that we will have access to both catalog of courses. This was a lie.

I paid for Linuxacademy yearly subscription to access their AWS Architect Pro and Devops Pro courses. 

**When I logged in a few days ago I found out that ACG removed 50 hour Aws Architect Pro Linuxacademy course by Adrian Cantrill and replaced it with their ACG inferior 14 hour course by Scott Pelter**

**ACG removed 32 hour Devops Pro course and replaced it with their garbage 6 hour course. In actuality itâ€™s only 4 hours!! Because they sneakily marked each section quiz as 4 hours long and added it to course total.**

This is clearly not what I and other Linuxacademy members paid for. We would like the content that we paid for. Ryan Kroonenburg should be ashamed of himself for scamming people.

I opened a ticket and was told by ACG rep that if I didnâ€™t watch any video from Linuxacademy AWS Pro courses before then I wonâ€™t have access to them. Which is completely the opposite of what we were told when ACG took over.

They are slowly replacing all LinuxAcademy courses with shorter, vomit inducing ACG products. 

**Also they sneakily inflate course length by making their quizzes as 4 hour long each. For example there are 6 quiz for AWS Devops Pro exam. So 6 x 4 is 24 hours. The total length of AWS Devops pro course advertised by ACG is 27 hours. So there is only 3 hours of content. No really, go check!**

Linux academy had such great courses and content. Acloudguru is completely destroying all of its credibility and scamming people on top of it. I advise not to get any subscription with them. 

Rather support people like Stephen Maarek, Adrian Cantrill, Eissa Sharif, Neal Davis etc.",1600535539.0,659
3,aws,https://i.redd.it/gqvebjo9hf9b1.jpg,What does he mean by â€œtech stack is on an AWS S3 clusterâ€?,,1688249747.0,652
4,aws,https://www.reddit.com/r/aws/comments/9pefq8/aws_support_now_officially_on_reddit/,AWS Support now officially on Reddit!,"Hello /r/aws,

AWS Support has officially landed! 

To better support the thriving community here, we have created an official AWS Support account! We will specialize in **Account & Billing questions** and do our best to resolve your issue, address your feedback, or point you toward resources that can help.

Please bear with us as we get this program off the ground, and let us know how weâ€™re doing and how we can improve your experience with us. Shout out to moderator u/ckilborn for helping us get started!

Thanks for building on AWS!",1539905421.0,616
5,aws,https://www.reddit.com/r/aws/comments/rb1xrd/500502_errors_on_aws_console/,500/502 Errors on AWS Console,"As always their Service Health Dashboard says nothing is wrong.

I'm getting 500/502 errors from two different computers(in different geographical locations), completely different AWS accounts.

Anyone else experiencing issues?

&#x200B;

ETA 11:37 AM ET: SHD has been updated:

>8:22 AM PSTÂ We are investigating increased error rates for the AWS Management Console.  
>  
>8:26 AM PSTÂ We are experiencing API and console issues in the US-EAST-1 Region. We have identified root cause and we are actively working towards recovery. This issue is affecting the global console landing page, which is also hosted in US-EAST-1. Customers may be able to access region-specific consoles going to [https://console.aws.amazon.com/](https://console.aws.amazon.com/). So, to access the US-WEST-2 console, try [https://us-west-2.console.aws.amazon.com/](https://us-west-2.console.aws.amazon.com/)

ETA: 11:56 AM ET: SHD has an EC2 update and Amazon Connect update:

>8:49 AM PSTÂ We are experiencing elevated error rates for EC2 APIs in the US-EAST-1 region. We have identified root cause and we are actively working towards recovery.  
>  
>8:53 AM PSTÂ We are experiencing degraded Contact handling by agents in the US-EAST-1 Region.

Lots more errors coming up, so I'm just going to link to the SHD instead of copying the updates.

[https://status.aws.amazon.com/](https://status.aws.amazon.com/)",1638891679.0,558
6,aws,https://www.reddit.com/r/aws/comments/liiki3/aws_support_is_better_than_any_other_vendor/,AWS Support is better than any other vendor support I've used.,"I've been working professionally in IT for a decade in a variety of roles. I've opened tickets with Microsoft, VMware, Novell, Oracle, SolarWinds, Dell, EMC, NetApp, Red Hat, and many more. I've been working full time with AWS for over four years now and their Support has ALWAYS been top notch.

Yesterday's example: We're looking at using the new S3 PrivateLink (Interface Endpoint) functionality and our devs have a use case that uses S3 Presigned URLs. We haven't used them much publicly let alone with PrivateLink, but were able to get a Presigned URL to work and download files via the Interface Endpoint, except we kept getting SSL errors no matter the different approaches we tried due to certificate not matching our vpce- hostname. I confirmed our dev's experiences so I decided to open a ticket to see if AWS had a solution. I opened a chat and talked to someone within 5min, they understood the issue and my goal, they reproduced it themselves while chatting (I assume in their own environment). They did as much internal research as they could but found no solution so escalated to the product team. I feared this would be kicked back as a known limitation. This morning they got back to me with a straightforward answer that you need to make the request to a specific subdomain under endpoint hostname and it worked flawlessly.

Let's review:

* Talked to a person within 5 min of submitting a ticket
* They spoke clear, concise English
* Tried to understand my problem and reproduced it
* Used the tools at their disposal to try to resolve my issue
* Escalated to experts when they could not resolve
* Followed up within 24hrs with a solution including detailed instructions to resolve my issue

When was the last time you got support like that from a big name company? When I was still working with Oracle I wouldn't even bother with their support infrastructure anymore due to bad communication, responding off business hours, slow response times, constantly pushing issue back on customer, and the general vibe that they just want the customer to go away. Others may get you across the finish line, but only after several business days of back-and-forth sending logs and phone calls, webexes, etc.

Anyway, other people probably have had less stellar experiences with AWS Support, but every single time I've interacted with them I just feel more validated that AWS is the right place for us to focus instead of our smaller Azure environment. AWS touts putting the customer first and for me, that shows in everything they do.",1613157846.0,514
7,aws,https://i.redd.it/d6gghoyhyyp81.jpg,Trouble choosing the services (read comment),,1648406391.0,490
8,aws,https://www.reddit.com/r/aws/comments/ii8ts4/the_new_route_53_ui_is_terrible/,The new route 53 UI is terrible,"Didn't I already post this? Oh wait no, I'm sorry. That was the new calculator UI.

AWS...please stop with all the wizard nonsense. Again. I don't need a wizard to hold my hand through creating a TXT record. I need something simple, or as you now call it, the ""old console"". I get the desire to create an experience, but please do it where it is warranted. Who in the community is asking for you to complicate the process of creating DNS records? I would rather you take us back to the days of editing BIND files with VIM than have to work in your new console. And I am not alone! A colleague of mine today just shared his feelings to me about your new console. He said, "" real DNS ballers edit BIND files with vim"". If you need a wizard to create DNS records, you should not be creating DNS records.",1598627567.0,489
9,aws,https://i.redd.it/5jm26apleai71.png,"Fun fact: type ""lamdba"" into your AWS search bar to find all documentation and articles where ""lambda"" is misspelled",,1629366939.0,474
10,aws,https://reinvent.awsevents.com,re:Invent 2020 will be free and virtual!,,1596048947.0,451
11,aws,https://www.reddit.com/r/aws/comments/ecf5i3/were_reddits_infrastructure_team_ask_us_anything/,"We're Reddit's Infrastructure team, ask us anything!","Hello r/aws!

The Reddit Infrastructure team is here to answer your questions about the the underpinnings of the site, how we keep things running, how we develop and deploy, and of course, how we use AWS.

**Edit: We'll try to keep answering some questions here and there until Dec 19 around 10am PDT, but have mostly wrapped up at this point.** Thanks for joining us! We'll see you again next year.

Proof:

[It us](https://preview.redd.it/a52e6qpouf541.jpg?width=4032&format=pjpg&auto=webp&s=45084b3b3e84806bf2f33a68abd91241c33bf27c)

Please leave your questions below. We'll begin responding at 10am PDT.

AMA participants:

u/alienth

u/bsimpson

u/cigwe01

u/cshoesnoo

u/gctaylor

u/gooeyblob

u/kernel0ops

u/ktatkinson

u/manishapme

u/NomDeSnoo

u/pbnjny

u/prakashkut

u/prax1st

u/rram

u/wangofchung

u/asdf

u/neosysadmin

u/gazpachuelo

As a final shameless plug, I'd be remiss if I failed to mention that we are [hiring](https://www.redditinc.com/careers) across numerous functions (technical, business, sales, and more).",1576687912.0,425
12,aws,https://aws.amazon.com/message/11201/,Summary of the Amazon Kinesis Event in the Northern Virginia (US-EAST-1) Region,,1606560339.0,409
13,aws,https://i.redd.it/kdzk8579cjv31.png,I made a chrome extension to color the console header depending on the region. Do you find the idea interesting ?,,1572378919.0,409
14,aws,https://www.reddit.com/r/aws/comments/m77p5g/aws_cognito_amplify_auth_bad_bugged_baffling/,"AWS Cognito & Amplify Auth - Bad, Bugged, Baffling","## What this article is about

I'm going to express my dissatisfaction with **AWS Cognito** and **Amplify Auth**. If you intend to use these services in the future, or you're already using them, you can probably get something out of reading the article, potentially save yourself some hair pulling.

I'll try to be as objective as I can be in my criticism. I don't have a dog in this race. I don't represent anyone. I use these services every day. If some of these bugs are fixed, I'll be a happy camper.

If you want to make edits to the article you could do it by opening an issue or pull request on [github](https://github.com/bobbyhadz/bobbyhadz.com/blob/master/src/blog/aws-cognito-amplify-bad-bugged.md)

## The change email functionality has been bugged for ~ 3 years

It's very common to implement auth with email as a username, unsurprisingly **AWS Cognito** supports this behavior.

[email sign in](https://preview.redd.it/7tb151qxpmn61.png?width=1423&format=png&auto=webp&s=29ff615f4ff21ca98474885a03741ec925fa322c)

You wouldn't want someone to register **with an email they don't own**, it's not secure and enables a **user to reserve emails they don't own** and block the actual email owners. Therefore you would need an email verification step (like every other site on the internet). Cognito also provides this functionality:

[require email verification](https://preview.redd.it/kixran89qmn61.png?width=1351&format=png&auto=webp&s=68250edac8dab249384d37530270b2881d995917)

Ok so what's the problem?

1. The user **requests an email change**, but **doesn't verify the new email** with the **verification code**
2. Cognito automatically updates the email attribute in the user pool, even though it wasn't verified.
3. If the user then logs out, they can only log in with their new - **not verified email**
4. The **new, not verified email** is already taken in the user pool, which blocks any users who might have that email from using your website.
5. The old email the user used is now available, in case someone decides to grab that one.

The expected behavior would be:

## Resolved

1. The user requests an email change
2. The user clicks on the link sent to their new email address
3. AWS Cognito verifies the email and updates the `email` attribute in the user pool

## Rejected

1. The user requests an email change
2. The user doesn't click on the link sent to their email address
3. AWS Cognito does nothing

Why did cognito change my email to `john@gmail.com` if I never verified it?

[change email bug](https://preview.redd.it/g6g3a0chqmn61.png?width=1212&format=png&auto=webp&s=9efdd29a81830387d7dbf5e5f3bcccaa951530ce)

Why am I able to log into my application as `john@gmail.com`?

[logged in as john@gmail.com](https://preview.redd.it/5edaj3jjqmn61.png?width=1285&format=png&auto=webp&s=9c5faa190765f3a069447d083a0fa1fea57899c6)

So I can log in with an email I haven't verified, even though I explicitly selected that I want users to verify their email.

This [issue](https://github.com/aws-amplify/amplify-js/issues/987) has been open for approximately 3 years.

Let's look at the source and see how we would tackle it:

## Default behavior

        if (user.requestsEmailChange()) {
          sendConfirmationEmailToNewEmail();
          updateUserEmailToNewEmail();
        }

## Proposed changes

        if (user.requestsEmailChange()) {
          sendConfirmationEmailToNewEmail();
        }
    
        if (user.hasClickedConfirmationLink()) {
          updateUserEmailToNewEmail();
        }

All I can say is hopefully this gets fixed some day, let's move on.

## The baffling custom email messages default behavior

When a user registers, requests an email change, requests a password reset etc, **we have to send them an email**. The default email cognito sends looks like:

[default email](https://preview.redd.it/nqh4renvqmn61.png?width=525&format=png&auto=webp&s=cd13c05d0793fc1e72f9215f3631927f2c3425bd)

**You would probably want to customize this email**. The way to do this in cognito is to use a `Custom message` lambda trigger.

That's all good, however one day I updated my custom lambda trigger and added a custom html string email template I'd send to my users. **After I made the update** I tested it and **I was still getting the default behavior** with the one liner email of type `The verification code to your new account is 183277`.

So I spent the next 4-5 hours debugging and it turns out the reason for this was that **the maximum length for custom email messages is** `20,000 UTF-8 characters` \- [docs](https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pool-settings-email-verification-message-customization.html).

So the way they decided to handle the case where I send **21,000 UTF-8 characters** is to **ignore my custom message** and **send their default message**, without giving me any indication as to what the cause was.

It's very easy to reach and surpass the limit, especially if you use a templating language to write your emails. So **let's say that for some crazy reason, the limit of 20,000 characters made sense**,

>shouldn't the default behavior be to send you an error indicating the problem?

Instead they send you an email of form: `Your code is 123.`. And you have to debug a custom cognito trigger and figure out:

>Oh, the reason it doesn't work is because I'm sending 21,000 UTF-8 characters and not 19,000, now I understand.

Now I need a custom trigger for my custom trigger to count the UTF-8 characters and alert me if they're more than 20,000, otherwise I'd send a one liner email in production and get fired.

They can **change this behavior to throw an error and inform the developer**, like tomorrow, and the result would be **hundreds of developer hours saved**.

What makes this even more confusing is, **there are actually multiple reasons** as to why **they silently ignore your custom email** template and send the default one:

1. [Having verification type set to link](https://github.com/amazon-archives/amazon-cognito-identity-js/issues/521)
2. [Trying to access event.userName](https://stackoverflow.com/questions/61514305/aws-cognito-custom-email-message-with-lambda-trigger-being-overwritten)
3. [A million of other reasons](https://stackoverflow.com/questions/56865198/how-to-send-a-custom-message-for-custommessage-admincreateuser-trigger)

So many developer hours wasted for no reason, is it that hard to handle the error and inform the developer?

It makes me wonder who is the **target audience of this default behavior**, is it the **end user** or is it **the developer**?

* The **end user** gets a one liner of type `Your code is 123.`, to say that's confusing would be an understatement
* The **developer** implements a custom function with a custom email and gets the default one line email. Now you're **right where you started** but you've wasted a couple of hours.

Let's look at the source:

## Default behavior

        const NICE_ROUND_NUMBER = 20000;
        
        if (email.message.length > NICE_ROUND_NUMBER) {
          return `Your code is ${Math.random().toFixed(4) * 10000}`;
        }

## Proposed changes

        if (email.message.length > NICE_ROUND_NUMBER) {
          throw new Error(
            `For some reason the maximum length of emails is 
            ${NICE_ROUND_NUMBER} and your email is ${email.message.length}
            characters long.`,
          );
        }

This would be another easy fix for Cognito. Anyway let's move on.

## Custom attributes are a MESS

When you want to **store a property on a user** that's **not included in the default provided cognito ones**, you have to use a **custom attribute**, i.e. add a boolean `isAdmin` to your user.

However it's not that simple, because there are huge inconsistencies between the types of custom attributes said to be supported.

1. [Cognito docs](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-settings-attributes.html#user-pool-settings-custom-attributes) and the console say:

* Each custom attribute can be defined as a `string` or a `number`.
* Each custom attribute **cannot be removed or changed once added** to a user pool.

[custom attributes console](https://preview.redd.it/93zwyoymrmn61.png?width=1432&format=png&auto=webp&s=6f45646a0bd1ff2aebd5fc5cbef1c62d1624b1e0)

Okay so I guess custom attributes support only `string` and `number` type and I have to be very careful when picking the type, because **I can't remove / update the custom attribute later**, which means that **the only way would be to delete and recreate my user pool**.

2. [Cloudformation docs](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cognito-userpool-schemaattribute.html#aws-properties-cognito-userpool-schemaattribute-properties) and [CDK docs](https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-cognito.ICustomAttribute.html#interface-icustomattribute)

* Allowed values: `Boolean` | `DateTime` | `Number` | `String`

I guess they just didn't implement the `boolean` and `datetime` types in the console yet, but they are supported by `cloudformation` and `CDK`.

I mean **if they aren't supported I'm gonna get an error** and my **stack will be safely rolled back**, right? Let's try:

        this.userPool = new cognito.UserPool(this, 'userpool', {
          // ... other config
          {
            myBoolean: new cognito.BooleanAttribute({mutable: true}), // 
            myNumber: new cognito.NumberAttribute({mutable: true}), // 
            myDate: new cognito.DateTimeAttribute({mutable: true}), // 
          },
        }

My stack update actually **succeeded**, let's open **the console** and see what happened:

https://preview.redd.it/8rlsom8urmn61.png?width=1409&format=png&auto=webp&s=eda4156e0e3af2e4e7a52489cc529d62b6cd163a

So at this point I'm thinking, **I guess they implemented the other types** as well, they **just didn't update the console interface, right**? Let's log into our application and see if the types are supported.

First we'll try a custom attribute boolean:

        const profileAttributes = {
          'custom:myBoolean': true,
        };
        
        return Auth.updateUserAttributes(user, profileAttributes);

[custom attribute boolean error](https://preview.redd.it/uoqgy5u1smn61.png?width=971&format=png&auto=webp&s=fe1e614dae97ad00c3df878c0137aec9ab37d8e2)

Okay, we get an error: **TRUE\_VALUE can not be converted to a String**, I guess booleans are not supported? I mean **CDK** and **Cloudformation** both **said booleans were supported**, the stack update went through with the boolean value, I guess after all they're not supported, too bad I **can't update/remove this attribute now**.

Let's try with a number, the number type is supported according to **CDK/Cloudformation/Cognito docs/Cognito Console**. There's no way it doesn't work, right?

        const profileAttributes = {
          'custom:myNumber': 42,
        };
        
        return Auth.updateUserAttributes(user, profileAttributes);

[custom attribute number](https://preview.redd.it/1z4crt67smn61.png?width=1013&format=png&auto=webp&s=7630fb27574118bb9ac7daa2483fc5fda6ae6b1d)

So we got an error: **NUMBER\_VALUE can not be converted to a String**.

I can't use a number either? I guess not. But all docs said I could. It turns out the problem is in my code. Look at [this solution](https://github.com/aws-amplify/amplify-js/issues/2958#issuecomment-497348646)

>All I had to do is wrap my number into quotes, like this '42'

[custom attribute number-string](https://preview.redd.it/gll1f7sbsmn61.png?width=938&format=png&auto=webp&s=ad1460fb8c315f5dba73a23276c7d743d6ebf770)

All you have to do is **wrap your number into quotes** \- `'42'`, in other words convert your number to a `string`, so that you can use a `number` type for your custom attributes 

What the `number` type actually means is - they try to parse your `string` input as a `number` and if it fails, it throws an error. You then are responsible to parse the `string` into a `number`, for your conditional checks all throughout your application code.

## Default behavior

>**Cognito docs/console**: Custom attributes can be defined as string or a number  
>  
>**CDK / Cloudformation docs**: Custom attributes can be Boolean, DateTime, Number or String

## Proposed behavior

>Custom attributes are of type **string**. We provide a `number` constraint, which tries to **parse your string input as a number** and if it fails, it throws an error. You are then **responsible to parse the string into a number** for your conditional checks.

At least this time they throw errors and don't silently decide how to handle things.

Anyway, let's move on.

## Amplify Auth's bundle size

So I just finished building a website, and I ran some checks to analyze my bundle size. I was very surprised to see that the bundle size for my `next.js` application was approximately `~400Kb gzipped`. That's huge, I don't that many external libraries so I started investigating.

It turns our `300Kb gzipped` of my `400Kb` were from the module `@aws-amplify/auth`. They were including the same library named `bn.js` like 7 times - [github issue](https://github.com/aws-amplify/amplify-js/issues/7570#issuecomment-767639192)

https://preview.redd.it/8bhttyajwmn61.png?width=1919&format=png&auto=webp&s=8711f471feaa1331d6a7eeaaeed1d22443acc280

Initially I thought that's only 6 instances of `bn.js` being bundled, but **if you look closely**, **there's a cheeky 7th instance in the right top corner** of the node\_modules section.

Well this is a little annoying, but it's being worked on by the amplify team, [thanks, Eric Clemmons](https://github.com/aws-amplify/amplify-js/issues/7570#issuecomment-788405226)!

Update from 17.03.2021, it seems that this issue has been [fixed](https://github.com/aws-amplify/amplify-js/issues/7570#issuecomment-790050205) by the Amplify team! I have not had the chance to try it out yet(it was fixed today), but the issue was closed.

## Unverified emails of users registering with Google / Facebook OAuth

>I'm going to warn you OAuth with Cognito and Amplify is the worst, so if you have to implement it, prepare mentally.

* Everyone who ever implemented OAuth with Cognito and Amplify

You **need your users to have their email verified**, because, otherwise you can't use **Forgot Password** and some other functionality: 

&#x200B;

[reasons to verify emails](https://preview.redd.it/q27wg8eysmn61.png?width=1336&format=png&auto=webp&s=e9bdf8adb9ac3eb9dc06cdfce0c4413410605529)

So on your site you provide a functionality for users to register with **Google** or **Facebook** OAuth. Have you ever seen an implementation where you make the users who sign up with **Google** or **Facebook** confirm their email? No? Ok, that's the first one.

The [default behavior with cognito](https://github.com/aws-amplify/amplify-js/issues/5117#issuecomment-604729707) is:

>Amazon Cognito did state by default they assume that any email/phone number they get from the result of a federated sign up or sign in is not verified so they do not set any values for the attribute for the user. Another note, the returned attribute from the IdP also has to have the value be set to the string ""true"" in order for us to set email\_verified to true

So by default they assume that **facebook and google emails are unverified**. How secure, they don't verify the email of facebook/google users by default, right? But their email change functionality is broken, so it's neither here nor there.

Notice how he also noted that the custom attribute has to be set to the `string` **""true""**, I guess I'm not the only one getting confused about `string-booleans` and `string-numbers`.

In my opinion, if the **user has access to a google/facebook account** with the email `john-smith@gmail.com`, then both accounts - the cognito native and facebook/google should be with **email\_verified set to true**.

Let's look at **how we can verify the email of a user who registered with Facebook and Google**.

>Spoiler alert, it's going to be kind of difficult and **DIFFERENT**, between the different OAuth providers.

## Verify a Google registered user's email

Let's start with **Google**. You would think that the best way to verify a user's email, would be in the `pre-sign-up Lambda` trigger. You check **if the user who's trying to register comes from an external provider Google**, if they do, you know that they're the owner of the email so you set their email verified property to true.

According to the [docs](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-pre-sign-up.html#aws-lambda-triggers-pre-registration-example-2), you can verify the email something like:

        // Set the email as verified if it is in the request
        if (event.request.userAttributes.hasOwnProperty('email')) {
          event.response.autoVerifyEmail = true;
        }

The only problem is that [autoVerifyEmail doesn't work with identity Providers](https://github.com/aws-amplify/amplify-js/issues/5287)

Unlucky, buddy, so close.

Anyways eventually you figure it out, you have to provide an attribute mapping between Google's `email_verified` attribute and cognito's `email_verified` attribute.

        this.identityProviderGoogle = new cognito.UserPoolIdentityProviderGoogle(
          this,
          'userpool-identity-provider-google',
          {
            // ... other config
            attributeMapping: {
              email: {
                attributeName: cognito.ProviderAttribute.GOOGLE_EMAIL.attributeName,
              },
              custom: {
                email_verified: cognito.ProviderAttribute.other('email_verified'),
              },
            },
          },
        );

Problem solved, Google was easy money, let's now look at how we can verify a Facebook email, you kind of assume it would be the same for Facebook right? Well, you assume wrong, because Facebook doesn't have an `email_verified` attribute.

## Verify a Facebook registered user's email

Facebook doesn't keep state of an `email_verified` property. So you try your best, but you don't succeed, you start to look around for solutions on the internet.

Let's look at the [proposed solution from the cognito team](https://github.com/aws-amplify/amplify-js/issues/5117#issuecomment-663011185) for verifying a Facebook registered user's email:

>Amazon Cognito invokes Post Authentication trigger after signing a user, allowing you to add custom logic after authentication. Until the feature is released, you can update ""email\_verified"" attribute using ""AdminUpdateUserAttributes"" API in a Post Authentication trigger which you have already implemented. Please note once the user has sign-up, **this trigger will be executed for every future successful sign-in**.

Needless to say the `""feature""` of automatically verifying Facebook user emails never got released.

When you try to verbalize all this, it starts making sense -

>In order to verify the email of a user who registered with Facebook, you have to add a Post Authentication lambda trigger. The trigger runs every time the facebook user logs in, and verifies their email, now I understand 

You would think this makes no sense, why don't you just use the `Post Confirmation` trigger, which runs only after a user has successfully been registered? Well because you'd get a [race condition](https://github.com/aws-amplify/amplify-js/issues/5117#issuecomment-661546722) leaving your application in a silently broken state.

## Default behavior

>The emails of users who registered with Google / Facebook are not verified by default.

## Proposed behavior

>Flip the boolean folks, please. Ongoing **feature** request for flipping a boolean shouldn't take a year, right?

## Cognito / Amplify OAuth - Linking native to external users

When you provide both OAuth and email registration functionality, a user might register both ways - with their email and with their google account.

So how do you think cognito handles this by default, I mean surely **you wouldn't want to have 2 users in your user pool with the same email**. That **would be very confusing** for the user, they log with their email and add an item to their cart, then they log on their phone with google with the same email, and the item is not in the cart.

As you might have guessed **cognito doesn't handle this at all**, and the **default behavior** is you just have users with the same email that are **not related** to one another.

Can you think of a use case for a **user having 2 accounts with the same email**? No? Ok.

In cognito your **email account** might have attributes X,Y,Z and **Google**, or **Facebook** might not have those attributes on the user object. How would you handle that behavior for your users with 2 separate accounts with the same email in your application.

Let's think about this.

Scenarios 1 and 2:

1. User has already registered with cognito native and now they create a **Google** account, with the same email, we should:

* If there is an email that is equal to the email of the Google OAuth account in the User Pool - `Link those accounts`.
* verify their email, if the user has access to Facebook account with email `john@gmail.com`, then they own that email.

1. User registers with **Google**, we should:

* Create the **Google OAuth** account in the User Pool
* Create a **native cognito user** \- email account
* Link those accounts
* Verify the email

Now you **don't have 2 accounts for the same email** and **can use user attributes** across the different authentication providers - it's a no-brainer. You can **manage** user properties in your app, i.e. **shipping address, city, country, preferences**, etc, that you can't access from their google account. This also allows us to enable reset password functionality, in case the user forgets and tries to log in with their email address, everything just works. Wouldn't it be nice for everything to just work?

>You don't use a managed auth service to have to implement everything yourself. Why is the default behavior to always delegate to the developer.

The only good reason I can think of to not have your accounts with the same email linked by default is if you don't trust the identity provider requires email validation, that's their excuse - security. If the Identity Provider doesn't require email validation, then I could register with an email I don't own - i.e. [**bob@gmail.com**](mailto:bob@gmail.com) , I would come register in your application and steal bob's account, because I got linked to it automatically. Well **fortunately for us**, **both Google and Facebook require email validation**, so I'm leaning more towards the cognito team just couldn't bother.

## Default behavior:

>You have 3 SEPARATE, UNRELATED accounts with the email [bob@gmail.com](mailto:bob@gmail.com) \- a native cognito account, a Facebook account and a Google account.

## Proposed behavior:

>If a user registered with Google and they have a Cognito email account - link those accounts.  
>  
>If a user registered with Google and they don't have an email account, create the google account, create an email account and link those accounts.

I'm not going to get into how they handle email change functionality for linked accounts, we saw that they don't handle it for isolated email registered accounts, so I don't feel like beating a dead horse, if you have to implement it - unlucky buddy.

## OAuth registration with Amplify

The first time a user registers with an OAUTH provider they get an error:

[oauth registration error](https://preview.redd.it/u0ktxfg9umn61.png?width=1546&format=png&auto=webp&s=9de1befd2ff30c7be9bd6444b6d638c94983cb85)

Error: **Error handling auth response. Error: Already+found+an+entry+for+username+Google\_...**

You start looking for a solution and you see some of the issues and hundreds of the developer hours lost:

1. [Cognito Auth fails with ""Already found an entry for username""](https://stackoverflow.com/questions/47815161/cognito-auth-flow-fails-with-already-found-an-entry-for-username-facebook-10155)
2. [Integrate facebook/google login to userpool](https://github.com/aws-amplify/amplify-js/issues/5036)
3. [Unable to log in first-time Cognito User Pool users after a recent change](https://forums.aws.amazon.com/thread.jspa?threadID=267154)

And then you see the AWS Employee (it's in link number 3):

&#x200B;

[their plans](https://preview.redd.it/9dkye6fhxmn61.png?width=768&format=png&auto=webp&s=0a5aa32972835be49ed912fc07340a13187ae8fe)

>Our plans are to provide built-in support for linking between ""native"" accounts and external identities such as Facebook and Google when the email address matches.  
>  
>We do not provide timelines for roadmap items, but I will tell you this is an area under active development.

**3 years** later this feature still hasn't been added.

Legend has it this feature is still under active development, same as the change email bug fix. Can't give you a timeline right now, but know that if it takes this long it's gonna be good 

Anyway, the way to handle this error is to catch it on your redirect route, i.e. your `/` route and handle the error, by starting the OAuth flow again, and opening the OAuth window:

        const Home: React.FC = () => {
          const router = useRouter();
          useEffect(() => {
            if (
              router.query.error_description &&
              /already.found.an.entry.for.username.google/gi.test(
                router.query.error_description.toString(),
              )
            ) {
              handleGoogleLogin();
            } else if (
              router.query.error_description &&
              /already.found.an.entry.for.username.facebook/gi.test(
                router.query.error_description.toString(),
              )
            ) {
              handleFacebookLogin();
            }
          }, [router.isReady, router.query.error, router.query.error_description]);
        
          // rest...
        };

Hopefully they don't change their error messages because my brittle code would break instantly, unlucky buddy.

## All the small things - Amplify's error throwing

Speaking of error messages, **Amplify throws all kinds of error types** and signatures which is very unfortunate, because you have to catch these errors.

* Sometimes they `Promise.reject` with a string, like in their `currentAuthenticatedUser` method:

[current authenticated user error](https://preview.redd.it/26yc1fdpumn61.png?width=605&format=png&auto=webp&s=b3c8d4cfad9738e2f9c037180adf1288d328d5cc)

* Sometimes they throw an **object** that is not instance of `Error` (Error is a function type in JS), like in their `updateUserAttributes` method:

[update user attributes error](https://preview.redd.it/1wa2psfsumn61.png?width=1028&format=png&auto=webp&s=5297c3bc56fdbcba2e5bf6018f80b9a1b07bf431)

* Most of the time they throw an instance of `Error`

I try so hard to catch them all, but in the end I have to read their source code.

You kind of **expect to get an error** of the **same type** from the same package. Otherwise **you have to check for everything** all the time. They throw instances of Error 95% of the time and the just randomly sprinkle misc error types here and there.

## Default behavior:

>They throw various types of errors which bloats your catch block and leads to unhandled errors and bugs

## Proposed behavior:

>Please, just throw the same error type consistently

## The random unexplained errors

These are the errors you get and you can't reason about, because they make no sense whatsoever, you look at the clock, 5 hours have passed, you've made 0 progress, you're sweating profusely and have had too much coffee, now you won't be able to sleep and you'll have to think about cognito and amplify the whole night.

I'm only going to include 1 of these errors, because they kind of are all the same, not very interesting, once you encounter them you start googling around, if you find something - nice, if you don't - unlucky buddy.

When you have users register with OAuth providers, you can enable attribute mappings. I.e. the Google account `first_name` attribute to be mapped to Cognito's `first_name` attribute.

There's this attribute `preferred_username`, and when you map it using Google as OAuth provider, it works:

        this.identityProviderGoogle = new cognito.UserPoolIdentityProviderGoogle(
          this,
          'userpool-identity-provider-google',
          {
            // other stuff..
            attributeMapping: {
              preferredUsername: {attributeName: 'email'},
            },
          },
        );

The same attribute mapping, but for Facebook:

        this.identityProviderFacebook = new cognito.UserPoolIdentityProviderFacebook(
          this,
          'userpool-identity-provider-facebook',
          {
            // ... other stuff
            attributeMapping: {
              preferredUsername: cognito.ProviderAttribute.FACEBOOK_EMAIL,
            },
          },
        );

The only problem is you can't use the facebook mapping, it's bugged and causes an error:

[preferred username error](https://preview.redd.it/7kkyjw50vmn61.png?width=1027&format=png&auto=webp&s=02bfe54517eb74826188fc432294a7791669c135)

Error: errordescription=attributes+required&error=invalid\_request

I would have preferred, if the `preffered_username` attribute mapping didn't throw a **cryptic error** for no reason, but it is what it is, five hours later I figured it out.

There are other causes for this error as well, so best believe the select few that encounter it are in for a treat.

## End

Believe it or not there are other things I didn't include in this post, but no one is probably going to read the whole thing so I won't bother.

I use a **MANAGED** auth service to boost my productivity, well it's NOT working. Spending hours and hours debugging / implementing common sense ""features"" that should be the default behavior doesn't boost your productivity very much.

My **intent with this article is not to mock/offend anyone**. My **goal is to hopefully see some of these problems fixed** in the future. If these teams are understaffed, hopefully they get money to hire more people. I've spent hundreds of hours learning these services, so if I were to cut my losses, these are some significant losses I'd have to cut.

I've tried to be as objective as possible, **I don't work for a competitor**, I don't have a dog in this race, if cognito and amplify improve - my development experience improves.

If I've misunderstood/misrepresented something it was not intentional and if you correct me, I'll update the article.

If you made it this far, pat yourself on the back, hopefully you're more prepared when you encounter one of these issues. **Thank you for reading!**

Also how has your experience been with **Cognito** and **Amplify**?",1616007318.0,407
15,aws,https://www.reddit.com/r/aws/comments/rvi9a8/thanks_to_all_of_the_my_account_was_hacked_posts/,"Thanks to all of the ""My account was hacked!"" posts here, I finally setup MFA on all of my accounts","Just wanted to post a thank-you for all the hard lessons learned by the community. 

It was the final motivation I needed to setup MFA across all of my environments in all of my projects. 

I've been delaying the setup for months. Thanks for the motivation!

Hopefully this serves as a reminder to anyone else viewing this sub to setup MFA!!",1641260855.0,405
16,aws,https://www.teamblind.com/blog/index.php/2021/12/09/why-new-hires-make-more-money-existing-employees/,"A software engineer at Amazon had their total comp increased to $180,000 after earning a promotion to SDE-II. But instead of celebrating, the coder was dismayed to find someone hired in the same role, which might require as few as 2 or 3 YOE, can earn as much as $300,000.",,1639162979.0,397
17,aws,https://aws.amazon.com/certification/faqs/,Covid-19 AWS Certification Update: You can now take all AWS Certification exams with online proctoring,,1584996061.0,386
18,aws,https://www.reddit.com/r/aws/comments/mlfbcw/i_built_a_tool_which_automatically_suggests/,I built a tool which automatically suggests least-privilege IAM policies,"I'm building iam-zero, a tool which detects IAM issues and suggests least-privilege policies.

It uses an instrumentation layer to capture AWS API calls made in `botocore` and other AWS SDKs (including the official CLI) and send alerts to a collector - similar to how Sentry, Rollbar, etc capture errors in web applications. The collector has a mapping engine to interpret the API call and suggest one or more policies to resolve the issue.

I've worked with a few companies using AWS as a consultant. Most of them, especially smaller teams and startups, have overly permissive IAM policies in place for their developers, infrastructure deployment roles, and/or services.

I think this is because crafting truly least-privilege IAM policies takes a lot of time with a slow feedback loop. Trying to use CloudTrail [like the AWS docs suggest](https://aws.amazon.com/premiumsupport/knowledge-center/troubleshoot-iam-permission-errors/) to debug IAM means you have to wait up to 15 minutes just to see your API calls come through (not to mention the suggestion of deploying Athena or running a fairly complex CLI query). Services like IAM Access Analyser are good but they are not very specific and also take up to 30 minutes to analyse a policy. I am used to developing web applications where an error will be displayed in development immediately if I have misconfigured something - so I wondered, what if building IAM policies had a similar fast feedback loop?

The tool is in a similar space to [iamlive](https://github.com/iann0036/iamlive), [policy\_sentry](https://github.com/salesforce/policy_sentry/), and [consoleme](https://github.com/Netflix/consoleme) (all of which are worth checking out too if you're interested in making AWS security easier) but the main points of difference I see are:

* iam-zero can run transparently on any or all of your roles just by swapping your AWS SDK import to the iam-zero instrumented version or using the instrumented CLI
* iam-zero can run continuously as a service (deployed into a isolated AWS account in an organization behind an SSO proxy) and could send notifications through Slack, email etc
* iam-zero uses TLS to dispatch events and doesn't include any session tokens in the dispatched event ([AWS Client Side Monitoring](https://summitroute.com/blog/2020/05/25/client_side_monitoring/), which iamlive utilises, includes authentication header details in the event - however iamlive is awesome for local policy development)

My vision for the tool is that it can be used to give users or services zero permissions as a baseline, and then allow an IAM administrator quickly review and grant them as a service is being built. Or even better, allowing infrastructure deployment like Terraform to start with zero-permissions roles, running a single deployment, and send your account security team a Slack message with a suggested least permissions role + a 2FA prompt for a role to deploy the infrastructure stack.

iam-zero is currently pre-alpha but I am hoping to get it to a stage where it could be released as open source. If you'd be interested in testing it or you're having trouble scaling IAM policy management, I'd love to hear from you via comment or DM. Any feedback is welcome too.

Live demo: [https://www.loom.com/share/cfcb5c20ede94f3d9214abbd28fa7921](https://www.loom.com/share/cfcb5c20ede94f3d9214abbd28fa7921)

https://preview.redd.it/yx5lzel0ekr61.png?width=2676&format=png&auto=webp&s=90294cc62267d9ddd3604f347d02fe54c2d9a38b",1617725763.0,376
19,aws,https://www.businessinsider.com/leaked-document-amazon-salaries-job-offer-715400-2021-8,"A leaked Amazon document shows the maximum compensation a recruiter is allowed to offer some programmer job candidates, up to $715,400",,1629934735.0,370
20,aws,https://www.reddit.com/r/aws/comments/q0m97j/what_wonderful_times_we_live_in/,What Wonderful Times We Live In,"Caveat - not a technical post or question so much as a sort of love letter to the Cloud.

I'm 57 years old and I've been working in the data space for the last 25 years. My first database build was a tactical database in 1990 in dBase III when I was in the Air Force. From there I graduated to Sybase and then to SQL Server. Along the way I've picked up everything from Oracle to SQLite to MongoDB.

This weekend I'm working on a project that involves processing a 10GB json file and databasing it. If I had tried to do this on my MacBook, my laptop would have laughed at me, before it died. Instead, I put in a spot request  on AWS and ended up completing the project in about an hour for about $1.10.

To the folks who've grown up in a cloud first world, this might not seem like a big deal. But even having worked in AWS for five years now, this to me still feels a bit miraculous. Twenty five years ago, if you wanted to say, learn how to build a Linux cluster, you'd buy a book (a very large, heavy book which invariably cost $70) and plow your way through it. And, of course, it didn't do you much good unless you had access to the hardware (and software) to practice on. Learning an other than open source language meant, again, the obligatory doorstop tome and shelling out shekels for an SDK.

In 2021, an afternoon of youtube and some AWS cloud, storage and compute is enough to become well versed in a new skill.  This old dog learns new tricks every day....to me thats still miraculous.",1633281649.0,367
21,aws,https://www.reddit.com/r/aws/comments/h09wl5/dear_aws_stop_ruining_the_freaking_console_ui_rant/,"Dear AWS, stop ruining the freaking console UI [rant]","*I need to get this off my chest, and since this is one of the few places online where people that might share my view on this might see it, I figured it's a good place to go off.*

*If someone from AWS is actually reading this, please pay special attention to the last bit on accessibility, because I'm pretty sure most of the frustration is due to that.*

Dear AWS, please STOP ruining the console UI! I'm not the kind of person that hates change just cause I'm stubborn. If you were improving it, power to ya, but you're not. You are busy making the experience worse. I guess I should thank you because I've been telling coworkers for years to use the CLI and that it's better, and now you are going out of your way to prove my point and drive people there. But sometimes it's just simpler to view a dashboard or play around with a new service using the console. Well, it used to be.

Your transition over to the new UI aren't even smooth on some services. Take EC2 for instance. You rolled out the new look for the Autoscaling section, but most of the time when I navigate there I get the old UI with an error message. When I reload the page, the new UI loads and I can see my resources. Next, CloudWatch Logs. WHY THE HECK WOULD YOU MAKE IT LESS USER-FRIENDLY!? Usually you go to view logs when stuff is broken, often production systems, which is stressful enough. Now you've gone and changed the UI and made it worse. Something as stupid as switching between viewing logs as ""Text"" vs ""Row"" is now in a sub menu in a drop down, why?

That leads me to my next point, sub menus and drop downs. Everything is in a collapsible element. That's freaking annoying. Sometimes you want to copy some text to share with a colleague, but as soon as you click to highlight, the blooming thing expands or retracts  and moves the element. Ultimately you can do what you want to do, yes, but it takes longer. In high paced, high pressure environments, crap like that is something no one needs.

It's one thing to make something look better, but most people that uses AWS don't care about looks. We want functionality and ease of use. It can look like a dog's breakfast for all we care, it just has to work!!

**Accessibility**

As I said at the start, I'm sure most of my frustrations is because you are making the UI less user-friendly for people with vision problems. You are making it harder for me to do my job, and I really don't need anyone to do that.

The old UI was basic, simple, and it was really clear where one section ended and another started. There was less collapsable elements and hidden menus. Yes, sometimes you had to scroll till your fingers went numb, but at least it didn't require clicking on 4 different little arrows and two sub-menus to get to the info you want.

I highlight text that I want my screen reader to read out loud. But it feels like 70% of the time I try that technique with the new UI it doesn't work. The text is either some kind of link or action button that opens a collapsable element, or the reader doesn't pick it up as text. Now I know the first response to that last one will be ""maybe your screen reader is the issue."" But why then is it only on your website? I don't know what kind of UI framework you use, but it's not very accessibility-friendly. It's pretty much impossible to read text in a table. It either doesn't read, or it reads the entire table, no matter which cell I'm highlighting. The worst part is that you're now using this same thing for your documentation pages. I'm basically losing my mind cause I can't read the freaking docs!

Then there is the moving of buttons and options and inconsistent UI's. I'm not talking about the UI being inconsistent across services, it's always been like that. That's something I learned to love about the old UI. I'm talking about something like the Lambda console. Select a function and navigate to the ""Configuration"" tab. All the config sections are full screen-width blocks, except the X-Ray one. In addition to the screen reader, I use a screen zoom function. So I don't see the whole screen. So I basically scrolled up and down and up and down in search of the X-Ray section, thinking I'm not seeing it. Only to find out, nope, that one config block is sitting on the right side of the page, outside the view of the zoom. Again, you could say that's not your problem, but it kinda is. If all the configs were side-by-side, I would be hovering left to right all the way down the page.

The moving of buttons is one of those things that make me want to scream. With the old UI, most of the action buttons is on the left hand side at the top. Now you moved it to the right, but not on all pages. Why? Why would you move something just for the sake of moving it? ""It looks better there."", no it doesn't. It looks the same, it's just orange instead of blue and on the right instead of the left. Most people don't know this, but people with vision problems don't read all the menus/buttons. They memorize button names, link text, and the placement of it to speed up their workflow. Now I basically have to start over.

And finally let's get to colors, fonts, and shadows. The old UI, again, was basic. Black text on a white page, when highlighted it was substantially bolder, and when on a button it was Bol white text on a dark blue background. Here and there there was a menu with white text on black backgrounds. Now everything is a much more modern font, which is thinner and harder to read when highlighted since it doesn't get much bolder. Some pages have colors that are so light that's impossible to see white text, and pages are so busy to cram all the info into a single view, that everything just feels cramped and the font feels smaller.

I can go on, but I'd be pretty surprised if anyone made it this far. I also feel a bit better now, even though as soon as I navigate away from here I'm going back to the console and that kinda sucks.

As I said, I'm not a person that hates change. You updated the Support Center to have the new UI, and apart from the fact that I can't use my screen reader to read the table with all the open cases, it's nice. There's not much wrong with that page and you did a good job there. It's still user-friendly, even for me. Yeah the font/color issue is there too, but other than that.

I'm not the kind of person to just bitch and moan about something and not do something about it. This rant must sound like me bitching and moaning, and honestly, if I was allowed to use all the cuss words that came to mind, it probably would sound more like a rant. But I am willing to help wherever I can to help you improve the console experience. If I have to submit all my suggestions or take screen recordings to explain my situation, I'd gladly do that. I'm just not going to do it if it's going to get ignored. Rather ignore this then.

PS: It's not just AWS that's making this mistake. Even the folks here at Reddit made that mistake with their new look. It's impossible for me to use with my assistive technologies, so I'm still using the old UI. Yeah it looks like something that was created 20 years ago, but it works, and that's what matters.",1591792206.0,361
22,aws,https://www.reddit.com/r/aws/comments/d0hlt0/every_aws_customer_ever/,Every AWS customer ever. . .,"Day 1

""We're not going to rely on AWS specific features.""
  

3 months later
  

""OK, we need to use SQS, Lambda, ECS and DynamoDB but that's it!""
  

6 months later

""OK, we're an AWS shop.""",1567781127.0,364
23,aws,https://aws.amazon.com/service-terms/,AWS taking zombie apocalypse seriously in T&Cs Clause 42.10,,1613657779.0,352
24,aws,https://www.reddit.com/r/aws/comments/148mwol/useast1_down_for_anybody_else/,US-East-1 down for anybody else?,"502s on the console, lambdas not getting resources.

Uh oh",1686682976.0,353
25,aws,https://www.reddit.com/r/aws/comments/1aflm3n/aws_is_estimated_to_make_400_million_to_1_billion/,AWS is estimated to make $400 Million to $1 Billion with the new IPv4 charge,"Tomorrow, the AWS IPv4 rental charge will kick in at $43 per year per IP.  According to this article, it is estimated this new charge will make AWS $400M to 1$ billion a year!  
Other interesting observations:

* Amazon owns 132M ipv4 addresses 
* Worth about 4,6Billion $
* Tomorrow, the AWS IPv4 rental charge will kick in at $43 per year per IP.  According to this article, this new charge is estimated to make AWS $400M to 1$ billion a year!  
Other interesting observations.

More Details: [https://www.border0.com/blogs/ipv4-surcharge---your-aws-bill-is-going-up-this-february](https://www.border0.com/blogs/ipv4-surcharge---your-aws-bill-is-going-up-this-february) 

  
",1706718001.0,348
26,aws,https://www.reddit.com/r/aws/comments/qvm23y/hidden_aws_console_dark_mode/,Hidden AWS Console Dark Mode,"Hello fine folks, I found a little gem in the aws console cookie. Navigate to [console.aws.amazon.com](https://console.aws.amazon.com), open the chrome dev console, and navigate to the Application -> Cookies section. You should see an  entry for ""awsc-color-theme"", default value being ""light"". Just change this to ""dark"" and refresh!

https://preview.redd.it/alucgdj5t1081.png?width=853&format=png&auto=webp&s=49028e4c47a12f82b5be954f38dcc4ddfd20975b",1637107735.0,343
27,aws,https://www.reddit.com/r/aws/comments/ya0bl3/dark_mode_console_has_finally_arrived/,Dark Mode Console has finally arrived,"Announcement:  [https://aws.amazon.com/about-aws/whats-new/2022/10/dark-mode-support-aws-management-console/](https://aws.amazon.com/about-aws/whats-new/2022/10/dark-mode-support-aws-management-console/)

Looks pretty good too, just tried it out",1666375508.0,340
28,aws,https://aws.amazon.com/blogs/aws/announcing-aws-lambda-function-urls-built-in-https-endpoints-for-single-function-microservices/,Announcing AWS Lambda Function URLs: Built-in HTTPS Endpoints for Single-Function Microservices,,1649280208.0,346
29,aws,https://www.reddit.com/r/aws/comments/5wphqj/amazon_s3_and_amazon_ses_are_down/,Amazon S3 and Amazon SES are down,"As of 17:40 UTC, verified on us-east-1. Lots of people affected. Posting here in case anyone's wondering. Reports of EBS being down as well.

Update 17:52 UTC from amazon: 

>We are investigating increased error rates in the US-EAST-1 Region.

Update 18:16 UTC from amazon: 

> We've identified the issue as high error rates with S3 in US-EAST-1, which is also impacting applications and services dependent on S3. We are actively working on remediating the issue.

Update 18:33 UTC from amazon:

> We're continuing to work to remediate the availability issues for Amazon S3 in US-EAST-1. AWS services and customer applications depending on S3 will continue to experience high error rates as we are actively working to remediate the errors in Amazon S3.

Update 19:35 UTC from amazon:

> We have now repaired the ability to update the service health dashboard. The service updates are below. We continue to experience high error rates with S3 in US-EAST-1, which is impacting various AWS services. We are working hard at repairing S3, believe we understand root cause, and are working on implementing what we believe will remediate the issue.

Update 20:41 UTC: I'm starting to see services coming back online. 

Update 21:12 UTC from amazon:

> S3 object retrieval, listing and deletion are fully recovered now. We are still working to recover normal operations for adding new objects to S3.

Update 21:39 UTC: I'm starting to see PUTs coming back online.

Update 22:00 UTC: Most PUTs look like they are back online for me.

Update 22:08 UTC from amazon: 
> As of 1:49 PM PST, we are fully recovered for operations for adding new objects in S3, which was our last operation showing a high error rate. The Amazon S3 service is operating normally.

https://status.aws.amazon.com/

~~Edit: I just want to say, that status page is stupidly useless. Green checkmarks all the way in the middle of all of us-east-1 being down and the console being inaccessible.~~

Edit 2: RED checkmarks on the status page. This is a historic moment.",1488304453.0,332
30,aws,https://www.reddit.com/r/aws/comments/rocp33/mods_can_we_get_a_sticky_post_telling_anyone_that/,Mods: Can we get a sticky post telling anyone that visits this sub to setup MFA/lock down root creds/setup billling alerts/etc.?,"As per the title.  Everyday I step into this sub and see a post about someone getting ""hacked"".  Until AWS makes this default, at least newcomers can be reminded when they visit.",1640449752.0,335
31,aws,https://www.reddit.com/r/aws/comments/ec1t04/fyi_in_the_spirit_of_transparency_stepping_down/,"FYI - In the spirit of transparency, stepping down as a mod","Happy and sad news. 

It's been fantastic to see this sub grow and thrive over the last few years; growing from 25k members to over 100k! I've learned a ton and had some great experiences. However I've recently taken a job at AWS and this makes me feel conflicted about staying on as a mod in this community. Its hard to leave but I feel that mod duties like approving posts/comments, tagging posts, organizing events, etc should ultimately be handled by the community to remove any suspicion of bias.

Please reach out to [**u/Pi31415926**](https://www.reddit.com/user/Pi31415926/) if you would like to help out. See you in the clouds!",1576616051.0,329
32,aws,https://www.reddit.com/r/aws/comments/847imw/soby_popular_demandyou_can_now_make_pull_requests/,So...by popular demand...you can now make pull requests against AWS documentation on GitHub,The AWS docs are now open source! [Jeff Barrâ€™s blog post](https://aws.amazon.com/blogs/aws/aws-documentation-is-now-open-source-and-on-github/) has all the info on how to contribute. Each AWS service guide has its own repo in the [AWS docs organization](https://github.com/awsdocs) on GitHub. You can file issues if you have questions or submit pull requests if you have ideas to help improve the docs. You can watch a repo to monitor changes to those docs or for new feature updates to the service itself. Let us know if you have any questions!,1520973925.0,328
33,aws,https://www.reddit.com/r/aws/comments/rp80z9/when_aws_says_that_the_amazon_linux_kernel_is/,"When AWS says that the Amazon Linux kernel is optimized for EC2, they're not kidding","Just thought I'd share an interesting result from something I'm working on right now.

Task: Run ImageMagick in parallel (restrict each instance of ImageMagick to one thread and run many of them at once) to do a set of transformations (resizing, watermarking, compression quality adjustment, etc) for online publishing on large (20k - 60k per task) quantities of jpeg files.

This is a very CPU-bound process.

After porting the Windows orchestration program that does this to run on Linux, I did some speed testing on c5ad.16xlarge EC2 instances with 64 processing threads and a representative input set (with I/O to a local NVME SSD).

Speed on Windows Server 2019: ~70,000 images per hour

Speed on Ubuntu 20.04: ~30,000 images per hour

Speed on Amazon Linux 2: ~180,000 images per hour

I'm not a Linux kernel guy and I have no idea exactly what AWS has done here (it must have something to do with thread context switching) but, holy crap.

Of course, this all comes with a bunch of pains in the ass due to Amazon Linux not having the same package availability, having to build things from source by hand, etc. Ubuntu's generally a lot easier to get workloads up and running on. But for this project, clearly, that extra setup work is worth it.

Much later edit: I never got around to properly testing all of the isolated components that could've affected this, but as per discussion in the thread, it seems clear that the actual source of the huge difference was different ImageMagick builds with different options in the distro packages. Pure CPU speed differences for parallel processing tests on the same hardware (tested using threads running https://gmplib.org/pi-with-gmp) *were* observable with Ubuntu vs Amazon Linux when I tested, but Amazon Linux was only ~4% faster.",1640559258.0,319
34,aws,https://www.amazon.com/s?i=courses&rh=p_27%3AAWS+Training+%26+Certification&fbclid=IwAR1DccV2NwGhHLjXyqGrptmxECyAQFM2rFoDhO9z_H6kvZV_FviITsBzr_Q&ref=nav_ya_signin,Amazon AWS Certifications Courses Worth Thousands of Dollars are available FREE on Amazon Store.,,1667384219.0,311
35,aws,https://reinvent.awsevents.com/health-measures/,AWS is now requiring all attendees to re:invent to show proof that they're fully vaccinated and wear masks when not eating or drinking,,1631034447.0,307
36,aws,https://aws.amazon.com/blogs/developer/mocking-modular-aws-sdk-for-javascript-v3-in-unit-tests/,"When AWS SDK for JS v3 came out, I created a mocking library for it. Now it's officially recommended by the AWS JS SDK team and my post was published on the AWS blog!",,1627498433.0,308
37,aws,https://www.datacenterdynamics.com/en/news/aws-us-east-1-outage-brings-down-services-around-the-world/,AWS us-east-1 outage brings down services around the world,,1638897615.0,304
38,aws,https://aws.amazon.com/blogs/aws/new-use-mac-instances-to-build-test-macos-ios-ipados-tvos-and-watchos-apps/,EC2 Mac Instances,,1606796961.0,304
39,aws,https://github.com/SkullTech/aws-solutions-architect-associate-notes,"I passed the AWS solutions architect exam about an year ago, wanted to share my journey and my notes. It has already helped a lot of people, hope it also helps some of you.",,1600614506.0,302
40,aws,https://github.com/SkullTech/aws-solutions-architect-associate-notes,"Just passed the AWS solutions architect exam, here are my notes. Hope this helps some of you.",,1564670598.0,300
41,aws,https://www.reddit.com/r/aws/comments/hbztrc/i_wrote_a_free_app_for_sketching_cloud/,I wrote a free app for sketching cloud architecture diagrams,"I wrote a free app for sketching cloud architecture diagrams. All AWS, Azure, GCP, Kubernetes, Alibaba Cloud, Oracle Cloud icons and more are preloaded in the app. Hope the community finds it useful: [cloudskew.com](https://www.cloudskew.com/)

Notes:

1. The app's just a simple diagram editor, it doesn't need access to any AWS, Azure, GCP accounts.
2. You can see some sample diagrams [here](https://www.cloudskew.com/docs/samples.html).

[CloudSkew - Free AWS, Azure, GCP, Kubernetes diagram tool](https://preview.redd.it/9jm111zn1v551.png?width=1438&format=png&auto=webp&s=c33c6eb8c76a0c52408e0c672d36b6eac62a3fed)",1592569770.0,299
42,aws,https://www.businessinsider.com/amazon-managers-performance-reviews-hire-to-fire-internal-turnover-goal-2021-5,Why you should never work for Amazon itself: Some Amazon managers say they 'hire to fire' people just to meet the internal turnover goal every year,,1620832311.0,284
43,aws,https://nathanpeck.com/speeding-up-amazon-ecs-container-deployments/,ECS Container Deployments: Hands down the absolute best article I've found to explain ECS deployments. I wish more people read this article!,,1609775549.0,281
44,aws,https://i.redd.it/wbsltrzefuq91.png,Dear AWS: Please open a US Central Region,,1664477130.0,279
45,aws,https://www.zdnet.com/article/aws-said-it-mitigated-a-2-3-tbps-ddos-attack-the-largest-ever/,"AWS said it mitigated a 2.3 Tbps DDoS attack, the largest ever",,1592410151.0,280
46,aws,https://www.cnbc.com/2023/04/26/amazon-starts-layoffs-impacting-hr-and-aws-cloud-unit.html,AWS Layoffs Take Effect,,1682599330.0,273
47,aws,https://slack.engineering/slacks-outage-on-january-4th-2021/,Slackâ€™s Outage on January 4th 2021,,1612191861.0,270
48,aws,https://www.reddit.com/r/aws/comments/rh1rw7/another_aws_outage/,Another AWS outage?,Unable to access any of our resources in us-west-2 across multiple accounts at the moment,1639582544.0,272
49,aws,https://www.reddit.com/r/aws/comments/ekyj1a/please_use_the_right_tool_for_each_job_serverless/,Please use the right tool for each job - serverless is NOT the right answer for each job,"I'm a serverless expert and I can tell you that serverless is really really useful but for about 50% of use cases that I see on a daily basis. I had to get on calls and tell customers to re-architect their workloads to use containers, specifically fargate, because serverless was simply not an option with their requirements.

Traceability, storage size, longitivity of the running function, WebRTC, and a whole bunch of other nuances simply make serverless unfeasible for a lot of workloads.

Don't buy into the hype - do your research and you'll sleep better at night.

**Update:** by serverless I mean lambda specifically. Usually when you want to mention DynamoDB, S3, or any other service that doesn't require you to manage the underlying infrastructure we would refer to them as managed services rather than serverless.

**Update 2:** Some of you asked when I wouldn't use Lambda. Here's a short list. Remember that each workload is different so this should be used as a guide rather than as an edict.

1. Extremely low-latency workloads. (e.g. AdTech where things needs to be computed in 100ms or less).
2. Workloads that are sensitive to cold-starts. No matter whether you use provisioned capacity or not, you will feel the pain of a cold-start. Java and .NET are of prime concern here. It takes seconds for them to cold-start. If your customer clicks a button on a website and has to wait 5 seconds for something to happen you'll lose that customer in a heartbeat.
3. Lambda functions that open connection pools. Not only does this step add additional time to the cold-start, but there's not clean way of closing those connections since Lambda doesn't provide 'onShutdown' hooks.
4. Workloads that are constantly processing data, non-stop. Do your cost calculations. You will notices that Lambda functions will become extremely expensive if you have a 100 of them running at the same time, non-stop, 100% of the time. Those 100 Lambda functions could be replaced with one Fargate container. Don't forget that one instance of a Lambda function can process only 1 request at a time.
5. Long-running processes.
6. Workloads that require websockets. There's just too many complexities when it comes to websockets, you add a lot more if you use Lambdas that are short-lived. People have done it, but I wouldn't suggest it.
7. Workloads that require a lot of storage (e.g. they consistently download and upload data). You will run out of storage, and it's painful.",1578337351.0,271
50,aws,https://www.lastweekinaws.com/blog/an-aws-bill-analysis-changelogs-md/,"I publicly tore an AWS engineer's AWS bill apart to find savings, then shared the story with the world.",,1583959593.0,268
51,aws,https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_version.html,"Happy 10 year birthday to the current IAM policy language version (""Version"": ""2012-10-17"")",,1666028906.0,268
52,aws,https://dangoldin.com/2020/12/11/amazon-owns-more-than-2b-worth-of-ipv4-addresses/,Amazon owns more than $2B worth of IPV4 addresses,,1607790776.0,266
53,aws,https://diagrams.mingrammer.com/docs/getting-started/examples,Diagrams as code (Python) with AWS icon support,,1589498270.0,261
54,aws,https://github.com/onramper/action-deploy-aws-static-site,I built a GitHub Action that deploys static sites to Cloudfront,,1602543490.0,263
55,aws,https://m.economictimes.com/tech/technology/amazon-to-lay-off-9000-more-workers/amp_articleshow/98821965.cms,"Amazon is laying off another 9,000 employees across AWS, Twitch, advertising",,1679358615.0,260
56,aws,https://aws.amazon.com/about-aws/whats-new/2021/05/amazon-vpc-announces-pricing-change-for-vpc-peering/,VPC Peering traffic within the same AZ is now free ðŸŽ‰,,1620288362.0,258
57,aws,https://aws.amazon.com/blogs/aws/amazon-s3s-15th-birthday-it-is-still-day-1-after-5475-days-100-trillion-objects/,"Amazon S3â€™s 15th Birthday â€“ It is Still Day 1 after 5,475 Days & 100 Trillion Objects",,1615743662.0,257
58,aws,https://www.sentiatechblog.com/aws-re-invent-2020-day-3-optimizing-lambda-cost-with-multi-threading?utm_source=reddit&utm_medium=social&utm_campaign=day3_lambda,"I ran the numbers on Lambda multithreading. In my tests, doubling the amount of memory led to a 0,28% price increase and a 41,05% performance increase!",,1607345454.0,256
59,aws,https://www.reddit.com/r/aws/comments/jq3cha/am_i_the_only_one_who_hates_the_new_aws_console/,Am I the only one who hates the new AWS console design updates?,"I rarely use the old console except when I absolutely have to. It was slow and somewhat unappealing to look at. 

AWS just made some major updates to the console and I feel they did so with no user input. At least to me, everything I hate about the old one wasn't addressed or even made worse.

Is this just me or does anyone else feel same?",1604800917.0,255
60,aws,https://seanjziegler.com/how-to-build-a-free-static-resume-site-with-aws-s3-cloudfront-and-route-53/,"I wrote a guide on building your own resume site using AWS S3, CloudFront, and Route53. Its almost free to host and looks great on a resume.",,1589458343.0,253
61,aws,https://aws.amazon.com/blogs/compute/announcing-improved-vpc-networking-for-aws-lambda-functions/,Announcing improved VPC networking for AWS Lambda functions | Amazon Web Services,,1567539415.0,251
62,aws,https://www.reddit.com/r/aws/comments/7a5anz/we_are_the_aws_lambda_serverless_team_ask_the/,We are the AWS Lambda & Serverless team. Ask the Experts!,"Hi everyone,

Jeff Barr here. Weâ€™ve been seeing a ton of great questions and discussions on Lambda & serverless architecture more broadly, so weâ€™re here today to answer technical questions about building serverless applications with Lambda. Any technical question is game, from how to select the right framework, to why you should use serverless, to local testing and debugging, etc. 

Iâ€™m joined by:
* Ajay Nair (Product Manager)
* Chris Munns (Developer Advocate)
* Stefano Buliani (Solutions Architect)
* Bob Kinney (Software Engineer)
* George Mao (Technical Account Manager)
* Cecilia Deng (Software Engineer)
* Sanath Kumar Ramesh (Software Engineer)
* Rory Jacob (Software Engineer)
* Paul Maddox (Solutions Architect)
* Andy Katz (Product Manager)
* Tim Bray (Principal Engineer)

Weâ€™ll start answering questions at 11:00 AM PST for the next hour. 
Proof: https://twitter.com/awscloud/status/925781352020086784

UPDATE: Love all the great questions â€“ keep them coming! Weâ€™ll be here for another 30. 
UPDATE: That's a wrap! Thanks so much r/AWS for hosting us. Stay tuned for future events :) We'll continue to monitor this thread and try to get to any questions we missed.",1509558908.0,251
63,aws,https://www.reddit.com/r/aws/comments/bv70k8/aurora_postgres_disastrous_experience/,Aurora Postgres - Disastrous experience,"So we made the terrible decision of migrating to Aurora Postgres from standard RDS Postgres almost a year ago and I thought I'd share our experiences and lack of support from AWS to hopefully prevent anyone experiencing this problem in the future.

1. During the initial migration the Aurora Postgres read replica of the RDS Postgres would keep crashing with ""FATAL: could not open file ""base/16412/5503287\_vm"": No such file or directory "" I mean this should've already been a big warning flag. We had to wait for a ""internal service team"" to apply some mystery patch to our instance.
2. After migrating and unknown to us all of our sequences were essentially broken. Apparently AWS were aware of this issue but decided not to communicate it to any of their customers and the only way we found this out was because we noticed our sequences were not updating correctly and managed to find a post on the AWS forum: [https://forums.aws.amazon.com/message.jspa?messageID=842431#842431](https://forums.aws.amazon.com/message.jspa?messageID=842431#842431)
3. Upon attempting to add a index to one of our tables we noticed that somehow our table has become corrupted:  ERROR: failed to find parent tuple for heap-only tuple at (833430,32) in table ""XXX"". Postgres say this is typically caused by storage level corruption. Additionally somehow we had managed to get duplicate primary keys in our table. AWS Support helped to fix the table but didn't provide any explanation of how the corruption occurred.
4. Somehow a ""recent change in the infrastructure used for running Aurora PostgreSQL"" resulted in a random ""apgcc"" schema appearing in all our databases. Not only did this break some of our scripts that iterate over schemas that were not expecting to find this mysterious schema but it was deeply worrying that some change they have made was able to modify customer's data stored in our database.
5. According to their documentation at "" [https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER\_UpgradeDBInstance.Upgrading.html#USER\_UpgradeDBInstance.Upgrading.Manual](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_UpgradeDBInstance.Upgrading.html#USER_UpgradeDBInstance.Upgrading.Manual) "" you can upgrade an Aurora cluster by: ""To perform a major version upgrade of a DB cluster, you can restore a snapshot of the DB cluster and specify a higher major engine version"". However, we couldn't find this option so we contacted AWS support. Support were confused as well because they couldn't find this option either. After they went away and came back it turns out there is no way to upgrade an Aurora Postgres cluster major version. So despite their documentation explicitly stating you can, it just flat out lies. No workaround, explanation of why the documentation says you could or ETA on when this will be available was provided by support despite repeatedly asking. This was the final straw for us that led to this post.

Sorry if it's a bit ranting but we're really fed up here and wish we could just move off Postgres Aurora at this point but the only reasonable migration strategy requires upgrading the cluster which we can't.",1559306323.0,246
64,aws,https://aws.amazon.com/about-aws/whats-new/2023/04/amazon-s3-two-security-best-practices-buckets-default/,Amazon S3 beginning to apply two security best practices to all new buckets by default,,1681048427.0,244
65,aws,https://aws.amazon.com/about-aws/whats-new/2023/03/amazon-linux-2023/,Amazon Linux 2023 Officially Released,,1678920289.0,241
66,aws,https://blog.aboutamazon.com/innovation/aws-launches-initiative-to-accelerate-covid-19-diagnostics-research-and-testing,"AWS launches initiative to accelerate COVID-19 diagnostics, research, and testing",,1584710798.0,244
67,aws,https://fortune.com/2021/07/06/pentagon-discards-10-billion-cloud-deal-awarded-to-microsoft-amazon/,Pentagon discards $10 billion JEDI cloud deal awarded to Microsoft,,1625593350.0,245
68,aws,https://talawah.io/blog/extreme-http-performance-tuning-one-point-two-million/,Extreme HTTP Performance Tuning: 1.2M API req/s on a 4 vCPU EC2 Instance,,1621541283.0,245
69,aws,https://www.reddit.com/r/aws/comments/k48mzy/lambda_just_got_perms_billing/,Lambda just got per-ms billing,"Check your invocation logs! 

ï¿¼Duration: 333.72 ms Billed Duration: 334 ms",1606780326.0,244
70,aws,https://www.reddit.com/r/aws/comments/e2sujj/the_console_now_shows_region_eg_useast1_alongside/,The console now shows region (e.g. us-east-1) alongside the region name!,"As someone who doesn't have all the more obscure regions memorized, it's great to see these alongside the region name description, which is mostly useless for any sort of work I do.

https://imgur.com/7CUqyAW",1574916102.0,241
71,aws,https://aws.amazon.com/blogs/aws/migration-complete-amazons-consumer-business-just-turned-off-its-final-oracle-database/,Migration Complete â€“ Amazonâ€™s Consumer Business Just Turned off its Final Oracle Database,,1571146170.0,245
72,aws,https://aws.amazon.com/about-aws/whats-new/2021/09/amazon-ec2-global-view-console-regions/,Amazon EC2 now offers Global View on the console to view all resources across regions together,,1632866305.0,241
73,aws,https://www.cnbc.com/2019/10/25/microsoft-wins-major-defense-cloud-contract-beating-out-amazon.html,AWS misses $10B DoD JEDI cloud contract; Awarded to Microsoft,,1572046394.0,237
74,aws,https://www.reddit.com/r/aws/comments/irkshm/moving_25tb_data_from_one_s3_bucket_to_another/,"Moving 25TB data from one S3 bucket to another took 7 engineers, 4 parallel sessions each and 2 full days","We recently moved 25tb data from s3 bucket to another. Our estimate was 2 hours for one engineer. After starting the process, we quickly realized it's going pretty slow. Specifically because there were millions of small files with few mbs. All 7 engineers got behind the effort and we finished it in 2 days with help of 7 engineers, keeping the session alive 24/7

We used aws cli and cp/mv command.

We used 

""Run parallel uploads using the AWS Command Line Interface (AWS CLI)"" 

""Use Amazon S3 batch operations"" 

from following link 
 https://aws.amazon.com/premiumsupport/knowledge-center/s3-large-transfer-between-buckets/

I believe making network request for every small file is what caused the slowness. Had it been bigger files, it wouldn't have taken as long. 

There has to be a better way. Please help me find the options for the next time we do this.",1599944753.0,235
75,aws,https://aws.amazon.com/about-aws/whats-new/2023/02/enable-aws-systems-manager-default-all-ec2-instances-account/,Announcing the ability to enable AWS Systems Manager by default across all EC2 instances in an account,,1676819087.0,236
76,aws,https://i.redd.it/qt32qrir50o61.png,"On-demand, serverless Valheim server setup with AWS CDK, Discord Interactions and GitLab CI (repo, summary and article link in comments)",,1616172994.0,238
77,aws,https://www.reddit.com/r/aws/comments/cgty96/nightmare_scenario_employee_deletes_aws_root/,Nightmare Scenario: Employee Deletes AWS Root Account - How to Protect Yours,"I'm the CTO for a technology consulting company and this is the call I got this week: â€œOur entire AWS account is gone.  The call center is down, we canâ€™t log in - itâ€™s like it never existed!  How do we get it back?â€

One of our former clients, a multimillion dollar services provider, called us in a panic. They had terminated an employee, and in retaliation, that employee shut down their call center capabilities (hosted on Amazon Web Services via AWS Connect). The client was completely locked out and looking for the â€œundoâ€ button.

After some digging, and a favor from some friends at AWS, we discovered that the former employee had turned everyone off, then changed the email address and password associated with the root AWS account. This locked our client completely out of the account, and since everything was done with the right credentials, AWS couldnâ€™t reverse the damage.

Everything hit at once: they were frantically attempting to log in, and contact AWS, and deal with their entire operation being offline, and figure out exactly what had happened and why.

Their only option was to get the login from the former employee. They tried the nice way first, but by the end of the day the FBI was at his door. Once the account was back in our clientsâ€™ hands, they were able to turn the call center back on pretty quickly, but it still cost a full day.

The legal costs, user panic, and productivity loss could have been avoided by following a few best practices.

Here are three precautions you can take to safeguard your company against a security issue like this one:

**1.** **Practice Least Privileges**

The idea here is simple - everyone should have exactly the permissions they need and nothing more. Most cloud computing systems allow *very* fine-grained control of privileges. The Admin or Root account on any system shouldnâ€™t be used for daily work - write the password on a piece of paper, print out the backup MFA codes (more on that below) and stick it in a fireproof safe.

For the truly paranoid: put two safes in two locations.

After that, ensure that two people have enough access to create users and fix permissions - that way, someone can be out sick without grinding the company to a halt.

In this case, 5 people shared an email â€œgroupâ€ address and they all knew the password. That user had global access to everything, and when he was burned he decided to burn back.

*Create an admin or two, then set up other accounts for your employees with very specific limitations on what they can do.*

**2. Multi-Factor Authentication**

Multi-Factor Authentication (MFA) attaches a secondary authentication to your account (the email and password being the primary). You have likely experienced this when you were texted a code while signing up for something. *Turn it on everywhere that you can.*

In the book â€œ[Tribe of Hackers](https://www.amazon.com/Tribe-Hackers-Cybersecurity-Advice-World/dp/1793464189)â€, Marcus Carey sent 12 questions to 70 cyber security professionals.

When asked â€œWhat is the most important thing your organization can do to improve its security posture?â€ nearly all of them included requiring MFA wherever possible.

There are many forms of MFA, including text messages, apps on your phone, physical keyfobs, and encrypted thumb drives.

Itâ€™s very important to have a backup as well. Most systems will give you a set of â€œbackup codesâ€ which will each work 1 time. You can print them or put them in an encrypted note - but make sure you get them.

The importance of using multi-factor authentication cannot be overstated. Had the company used multi-factor authentication, this ex-employee would have never been able to log into the account and shut it down without them knowing about it.

*Turn on Multi-Factor Authentication*

**3. Offboarding Process**

Finally, ensure your company has a secure offboarding process. We encourage our clients to write up an â€œ86 procedureâ€ and review it quarterly.

The goal should be to strip all privileges in 5 minutes or less. When an employee is terminated, they should walk out of the termination meeting with no access and not be allowed back on their laptop.

Today, so many services exist that can become critical to a businessâ€™s operation. If you can afford to use something like Okta to manage these services you will have an easy off-button, but if not at least consider using your email provider (Google Apps and Outlook both provide this service).

*Create and review an offboarding process.*

Ultimately *you have to protect your data*. A few small steps can go a long way to ensuring one bad actor wonâ€™t negatively impact your business.

&#x200B;

As exciting as that phone call was, I don't want to take another one like that again!

&#x200B;

Edit: we originally posted this on [Medium](https://medium.com/@victoryteam/nightmare-scenario-employee-deletes-aws-root-account-29e28af15436) but wanted to share here too.",1563895231.0,236
78,aws,https://cloudbite.attejuvonen.fi/,Flashcards to learn AWS skills,,1622482570.0,237
79,aws,https://www.reddit.com/r/aws/comments/k4os73/i_dont_care_what_you_think_the_lambdaserverless/,"I dont care what you think, the lambda/serverless changes are the best thing in ReInvent/2020",1Ms billing? Lambda containers? That's it. That's all i wanted in life.,1606841729.0,237
80,aws,https://www.reddit.com/r/aws/comments/zbnaaf/attended_aws_reinvent_and_returned_with_covid/,Attended AWS reinvent and returned with Covid,"How many of you returned home with Covid positive after attending reinvent at Las Vegas?
I protected myself with a mask but some how the virus made it to me.
Hope rest of you all are feeling ok as I noticed the crowds are equal or bigger than 2019 and most of them were without masks.
I attended last year(2021) with same precautions and was covid negative due to the fact everyone had to mask up as per the attendee policy.",1670093054.0,233
81,aws,https://github.com/cschultz82/aws_encyclopedia,"AWS Encyclopedia -- A place to share all the useful AWS documentation, repos, and solutions you have bookmarked!",,1590721885.0,234
82,aws,https://www.reddit.com/r/aws/comments/ebmcah/a_cloud_guru_acquires_linux_academy/,A Cloud Guru Acquires Linux Academy,"This subreddit has been huge for the growth of both companies, so I thought it only fair to share this news as soon as it broke!

Release video: https://www.youtube.com/watch?v=XyUjjXZ9jwA

ACG release: https://acloud.guru/linux-academy

LA release: https://linuxacademy.com/news/press-release/acloudguru/

Q&A with the CEO to answer some of the questions posed by our students: https://info.acloud.guru/resources/qa-with-sam-k-acquisition-announcement-follow-up",1576535414.0,235
83,aws,https://www.reddit.com/r/aws/comments/x03vay/hacked_aws_account_is_facing_200000_in_charges/,"Hacked AWS Account is facing $200,000+ in charges after support ticket","After about a month of going back and forth with AWS support for my account, I am now being told I am liable for most of the total amount of the original bill of $213,000.  I've been in contact with AWS support for 4 weeks, and now they are refusing to answer my questions about the situation and continue replying with a copy / pasted message saying ""they've done everything they can"".

Needless to say, I'm living through one of the worst months of my life.  This bill is basically a life ending amount of money, and I'm not sure what to do at this point.  Initial messages from AWS were fairly encouraging basically saying this type of thing can happen from time to time, and I have no need to worry.  A similar story came out of my initial chat with a support representative at AWS.

I'm looking for any direction for other people who have gone through a similar incident, or any one else I might be able to contact since AWS support seems like it isn't willing to help anymore.

**9/14/2022 EDIT:**

After getting some help from people reaching out in this thread, I was able to get my account revisited by the Executive Customer Relations team again at AWS.  They seemed pretty responsive and thorough looking over my invoice.

After messaging with them back and forth for about a week or so, my entire invoice was waived!  I really appreciate anyone who was able to reach out and increase visibility on this issue to get AWS to take another look at the obviously unauthorized charges on my account.

I just deleted my AWS account today after having my invoice waived and confirmed with support that it is finally safe to do so.

**Moving Forward**  
It would be really nice to see Amazon make a change to AWS security to greatly reduce the frequency of problems like this from occurring.  I'm certainly no expert, but it seems like there is something that should be done.  These problems are fairly common from what I've observed over the past month or so, just usually not reaching 6 figures like mine did.

Someone in the thread made a suggestion to require MFA to be setup when creating a new account.  Would something like this or something with else similarly low friction be possible to increase the amount of security these very dangerous accounts can have?",1661715121.0,229
84,aws,https://www.reddit.com/r/aws/comments/b6q2m4/is_there_interest_in_setting_up_an_eli5_subreddit/,Is there interest in setting up an ELI5 subreddit specifically for AWS?,"For people new to AWS, all the services, acronyms and buzzwords can be a bit intimidating. Most discussions on here are very technical and feel advanced. For an experienced user, they are very handy, but not for a newbie.

It could be very handy to have a subreddit where people from a technical background can ask basic questions.

E.g. 

*ELI5: EBS v/s regular EC2 storage*

*ELI5: IAM roles and their purpose*

Of course there's plenty of documentation and stuff out there, but hearing it from people well-versed in it and with anecdotal examples could be invaluable. It's the reason why r/eli5 is so widely used.

_________________

EDIT. MOD u/ckilborn has setup a ELI5 flair. Ask away!",1553816111.0,233
85,aws,https://aws.amazon.com/solutions/case-studies/samsung-migrates-off-oracle-to-amazon-aurora/,Samsung Database Migration Case Study: 1.1 Billion Users across Three Continents from Oracle to Amazon Aurora with AWS Database Migration Service,,1592949640.0,228
86,aws,https://i.redd.it/nk56kiw9vda91.jpg,My depiction of ALB SSL offloading.,,1657303072.0,229
87,aws,https://v.redd.it/ak6491489gh81,We started using AWS SSO with external apps - there is no api so i had to automate the creation of over 500 apps,,1644692387.0,229
88,aws,https://www.reddit.com/r/aws/comments/nvlc4j/why_is_amazon_using_fastlycom_for_their_cdn_and/,Why is Amazon using Fastly.com for their CDN and not Cloudfront?,Title,1623206597.0,226
89,aws,https://github.com/Netflix/consoleme,ConsoleMe: Netflixâ€™s multi-account AWS console management tool,,1607866210.0,225
90,aws,https://www.reddit.com/r/aws/comments/11yw4og/application_load_balancer_now_supports_tls_13/,Application Load Balancer now supports TLS 1.3,"Just like it sounds, TLS 1.3 is now available on ALB.

https://aws.amazon.com/about-aws/whats-new/2023/03/application-load-balancer-tls-1-3/",1679518107.0,227
91,aws,https://aws.amazon.com/about-aws/whats-new/2022/12/amazon-rds-integration-aws-secrets-manager/,Amazon RDS announces integration with AWS Secrets Manager,,1671819654.0,225
92,aws,https://www.reddit.com/r/aws/comments/njuyc1/iam_zero_i_released_a_tool_which_automatically/,IAM Zero: I released a tool which automatically suggests least-privilege IAM policies,"A month ago I made a [post](https://www.reddit.com/r/aws/comments/mlfbcw/i_built_a_tool_which_automatically_suggests/) about IAM Zero, a tool which detects IAM issues and suggests least-privilege policies.

It uses an instrumentation layer to capture AWS API calls and send alerts to a collector - similar to how Sentry, Rollbar, etc capture errors in web applications. The collector has a mapping engine to interpret the API call and suggest one or more policies to resolve the issue.

The response from the post has been overwhelmingly positive (a big thankyou to all of you in the r/aws community for sharing your IAM pain points) - so I decided to spend the last month building IAM Zero to get it ready enough to be released as open source. I've also set up an open-source [company](https://commonfate.io/) to provide long-term support for the tool.

Website here: [https://iamzero.dev/](https://iamzero.dev/)

The initial release has automatic least-privilege advisories for S3 and DynamoDB, and will be scaled out to support all AWS services prior to a stable release. IAM Zero currently supports applications and scripts written in Python with support for other languages coming soon. Support for generating infrastructure-as-code deployment roles and requesting roles through the AWS web console are on the [roadmap](https://github.com/common-fate/iamzero/projects/1).

IAM Zero is released under the Apache 2.0 licence [on GitHub](https://github.com/common-fate/iamzero) \- we're planning on separating the least-privilege advisory library as a separate repository with an API which could be integrated into other projects too (currently the library is part of the main repository). Let me know if you'd be interested in this.

If you're interested in testing IAM Zero I'd love to hear from you via comment or DM. Any feedback is welcome too.",1621852790.0,225
93,aws,https://www.reddit.com/r/aws/comments/cmlza6/opinion_i_dont_care_about_new_services_i_just/,"[Opinion] I don't care about new services, I just want everything supported in CloudFormation for re:invent. Please Please Please AWS, invest much more dev work into getting CloudFormation supported for everything","Its such a big problem, I really wish they would put 95% of dev work into simply getting CloudFormation support to 99% - 100% for all services and require all new features to be supported in CloudFormation. I find it very frustrating that 3rd party products have better support than the native IaC service on AWS. The amount of times I have tried a service in CloudFormation and it not support some new feature that I really need is ridiculous.

And custom-resource lambda functions are messy, not well suited for name-spaced individual workspaces, time consuming to debug (can take up to 30 mins for cfn to delete if there is a bug) and clutter your AWS env if you need multiple lambda functions per cfn template which are appropriately namespaces.  


Hell even Open Source the CloudFormation codebase and let the community add missing features themselves using some diffing framework which CloudFormation much implement behind the scenes",1565065961.0,223
94,aws,https://addons.mozilla.org/en-US/firefox/addon/console-recorder/,Console Recorder for AWS - Records actions made in the AWS Management Console and outputs the equivalent CLI/SDK commands and CloudFormation template.,,1545511454.0,224
95,aws,https://www.reddit.com/r/aws/comments/182kunk/which_is_the_most_hated_aws_service/,Which is the most hated AWS service?,"Not with the intention of creating hate, but more as an opportunity to share bad experiences. Which is the AWS service you consider is the most problematic or have gave you most headaches working with in the past?",1700804493.0,220
96,aws,https://www.reddit.com/r/aws/comments/c8xgsc/i_am_stupefied_every_day_by_the_awfulness_of_the/,I am stupefied every day by the awfulness of the AWS web console,"For god's sake the AWS web console is horribly made.

Want to know how long I've put up with the image tab in the ECR repository view having stupid bugs;  go try it: if you have more than 10 image tags does sorting and searching work? -- no? -- has it been broken for three years? -- it has!

And if you assume-role into another account, CloudWatch will kick you back into the root view every time your session expires (which is every five minutes I think).

This happens because the CloudWatch dev team doesn't even assume-role into accounts (so I'm informed through insiders).

Many other areas of AWS will kick you back to the root view when assuming roles... thank god the EC2 view doesn't, or I'd murder someone.

And then I look at how other Amazon products like Prime act: compared to my smart TV's implementation of YouTube, prime sucks ass.  

Well no wonder.

PS: don't get me started on the random changes in their API.",1562210059.0,219
97,aws,https://aws.amazon.com/blogs/containers/aws-docker-collaborate-simplify-developer-experience/,AWS and Docker collaborate to simplify the developer experience,,1594355119.0,215
98,aws,https://reinventvideos.com,All re:Invent videos from 2012-2018. Sortable by likes and views,,1544143905.0,215
99,aws,https://aws.amazon.com/blogs/aws/a-new-aws-region-opens-in-switzerland/,The new AWS region in Switzerland is now open,,1667978045.0,214
