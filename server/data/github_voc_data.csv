source,url,title,body,user_html_url,created_at
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63044,Overlapping window with tf.data.experimental.make_csv_dataset,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.8

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Window dataset coming from the  tf.data.experimental.make_csv_dataset is not working as expected

### Standalone code to reproduce the issue

```shell
I'm trying to transform some data read from CSV files using tf.data pipelines and overlapping windows and its not working as expected. All the documentation is not providing clear explanation on how to deal with this case. The columns of the csv files are 'timestamp','open','high', 'low', 'close', 'volume'.


dataset = tf.data.experimental.make_csv_dataset(
    file_pattern=""/path/stock/*1min*.csv"",
    batch_size=1,
    num_epochs=1,
    shuffle=False,
    header=False,
    column_names=['timestamp','open','high', 'low', 'close', 'volume'],
    column_defaults=[tf.string, tf.float32, tf.float32, tf.float32, tf.float32, tf.float32]
).window(
    size=5,  # Number of rows per window
    shift=1,  # Stride for overlapping windows
    stride=1
)
```
This produces the following structure:
```
-WindowDataset
--OrderedDict
---VariantDataset
----Tensor (single element)
----Tensor...
```
This is not allowing me to transform in a simple way because OrderedDict has not batch method and I cannot flatten following the documentation.

```
dataset = tf.data.experimental.make_csv_dataset(
    file_pattern=""/path/stock/*1min*.csv"",
    batch_size=1,
    num_epochs=1,
    shuffle=False,
    header=False,
    column_names=['timestamp','open','high', 'low', 'close', 'volume'],
    column_defaults=[tf.string, tf.float32, tf.float32, tf.float32, tf.float32, tf.float32]
).window(
    size=5,  # Number of rows per window
    shift=1,  # Stride for overlapping windows
    stride=1
).flat_map(lambda window: window.batch(5))
```
Gives the following error:
```
AttributeError                            Traceback (most recent call last)

<ipython-input-47-46d1550f08a0> in <cell line: 1>()
     11     shift=1,  # Stride for overlapping windows
     12     stride=1
---> 13 ).flat_map(lambda window: window.batch(5))

19 frames

/tmp/__autograph_generated_filersrgq3km.py in <lambda>(lscope)
      3 
      4     def inner_factory(ag__):
----> 5         tf__lam = lambda window: ag__.with_function_scope(lambda lscope: ag__.converted_call(window.batch, (5,), None, lscope), 'lscope', ag__.STD)
      6         return tf__lam
      7     return inner_factory

AttributeError: in user code:

    File ""<ipython-input-47-46d1550f08a0>"", line 13, in None  *
        lambda window: window.batch(5)

    AttributeError: 'collections.OrderedDict' object has no attribute 'batch'
```
If I try to batch the datasets of the OrderedDict, I get the following error

---------------------------------------------------------------------------
```
AttributeError                            Traceback (most recent call last)

<ipython-input-59-16e14170c082> in <cell line: 25>()
     23 
     24 
---> 25 data = dataset.map(extract)
     26 
     27 

35 frames

/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor.py in __getattr__(self, name)
    259         tf.experimental.numpy.experimental_enable_numpy_behavior()
    260       """""")
--> 261     self.__getattribute__(name)
    262 
    263   @property

AttributeError: in user code:

    File ""<ipython-input-59-16e14170c082>"", line 3, in extract  *
        opens = data.get('open').flat_map(lambda x: x.batch(5))

    AttributeError: 'SymbolicTensor' object has no attribute 'batch'
```
This is becoming extremely confusing.

What would be a the right way to transform this structure so that I can later apply better transformations to build a timeseries dataset.
```


### Relevant log output

_No response_",https://github.com/ek-ex,2024-02-24T20:39:20Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63043,Running gemma model in Mac m1 gets xla_compile_on_demand_op error,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.15.0

### Custom code

Yes

### OS platform and distribution

macOS Sonoma 14.1.2

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

Macbook pro m1 16G

### Current behavior?

I expect get the model working, if I can help adding support to missing features I probably need some guidance but I can help ðŸ˜¸

Keras version: 3.0.5

I try same TensorFlow and Keras version using cuda on linux and I get the model working ðŸ™ˆ

### Standalone code to reproduce the issue

```shell
import keras
import keras_nlp
import numpy as np

gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(""gemma_2b_en"")
out = gemma_lm.generate(""Keras is a"", max_length=30)
print(out)
```


### Relevant log output

```shell
Low level error:

` W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_compile_on_demand_op.cc:292 : NOT_FOUND: could not find registered platform with id: 0x1320e1750`

Python get this error:


Traceback (most recent call last):
  File ""/Users/lmanrique/Try/gemma/main.py"", line 6, in <module>
    gemma_lm.generate(""Keras is a"", max_length=30)
  File ""/Users/lmanrique/miniconda3/envs/gemma/lib/python3.9/site-packages/keras_nlp/src/models/generative_task.py"", line 269, in generate
    outputs = [generate(x) for x in inputs]
  File ""/Users/lmanrique/miniconda3/envs/gemma/lib/python3.9/site-packages/keras_nlp/src/models/generative_task.py"", line 269, in <listcomp>
    outputs = [generate(x) for x in inputs]
  File ""/Users/lmanrique/miniconda3/envs/gemma/lib/python3.9/site-packages/keras_nlp/src/models/generative_task.py"", line 253, in generate
    return generate_function(x, end_token_id=end_token_id)
  File ""/Users/lmanrique/miniconda3/envs/gemma/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py"", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/Users/lmanrique/miniconda3/envs/gemma/lib/python3.9/site-packages/tensorflow/python/eager/execute.py"", line 53, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.NotFoundError: Graph execution error:
```
```
",https://github.com/lgemc,2024-02-24T02:45:55Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63042,NotFoundError: /home/chengjun/stylegan2-master/dnnlib/tflib/_cudacache/fused_bias_act_347e82e8919aeb0d5c7dc989e996c091.so: undefined symbol: _ZN10tensorflow12OpDefBuilder4AttrENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 1.14

### Custom code

Yes

### OS platform and distribution

linux ubuntu 22.04

### Mobile device

_No response_

### Python version

3.6

### Bazel version

_No response_

### GCC/compiler version

11.4.0

### CUDA/cuDNN version

10.0/7.6.5

### GPU model and memory

_No response_

### Current behavior?

When I tried to run stylegan2 on the server, I configured all the environments as required but got an error at runtime. 


### Standalone code to reproduce the issue

```shell
https://github.com/NVlabs/stylegan2

CUDA_VISIBLE_DEVICES=0 python run_training.py --num-gpus=1 --data-dir=/home/chengjun/datasets --config=config-f --dataset=my-custom-dataset --total-kimg=100000
this is my running command.
```


### Relevant log output

```shell
tensorflow.python.framework.errors_impl.NotFoundError: /home/chengjun/stylegan2-master/dnnlib/tflib/_cudacache/fused_bias_act_347e82e8919aeb0d5c7dc989e996c091.so: undefined symbol: _ZN10tensorflow12OpDefBuilder4AttrENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE
```
",https://github.com/shiqing1239,2024-02-24T00:58:12Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63037,`tf.raw_ops.UnravelIndex` can leads to eigen assertion failure,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.17

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04 LTS

### Mobile device

_No response_

### Python version

3.11.7

### Bazel version

6.5.0

### GCC/compiler version

clang 16

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Similar to #63036.

`tf.raw_ops.UnravelIndex` can leads to eigen assertion failure [here](https://gitlab.com/libeigen/eigen/-/blob/aa6964bf3a34fd607837dd8123bc42465185c4f8/unsupported/Eigen/CXX11/src/Tensor/TensorBroadcasting.h#L156):
```C++
eigen_assert(input_dims[i] > 0);
```
Note that it is executed without error message in release build.

### Standalone code to reproduce the issue

```Python
import tensorflow as tf

tf.raw_ops.UnravelIndex(
    indices=tf.constant([],dtype=tf.int32),
    dims=[1,1,1,1],
    name=None
)
```


### Relevant log output

Release build: outputs nothing

Debug build:
```shell
python: external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorBroadcasting.h:156: Eigen::TensorEvaluator<const Eigen::TensorBroadcastingOp<const Eigen::array<long, 2>, const Eigen::TensorReshapingOp<const Eigen::array<long, 2>, const Eigen::TensorMap<Eigen::Tensor<const int, 1, 1>, 16>>>, Eigen::DefaultDevice>::TensorEvaluator(const XprType &, const Device &) [Derived = const Eigen::TensorBroadcastingOp<const Eigen::array<long, 2>, const Eigen::TensorReshapingOp<const Eigen::array<long, 2>, const Eigen::TensorMap<Eigen::Tensor<const int, 1, 1>, 16>>>, Device = Eigen::DefaultDevice]: Assertion `input_dims[i] > 0' failed.
Aborted (core dumped)
```
",https://github.com/Sehun0819,2024-02-23T13:57:04Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63036,`tf.raw_ops.Substr` can lead to eigen assertion failure,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.17

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04 LTS

### Mobile device

_No response_

### Python version

3.11.7

### Bazel version

6.5.0

### GCC/compiler version

clang 16

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

The below code triggers eigen assertion failure [here](https://gitlab.com/libeigen/eigen/-/blob/aa6964bf3a34fd607837dd8123bc42465185c4f8/unsupported/Eigen/CXX11/src/Tensor/TensorBroadcasting.h#L156):
```C++
      eigen_assert(input_dims[i] > 0);
```
Note that it is executed without error message in release build.

### Standalone code to reproduce the issue

```Python
import tensorflow as tf

tf.raw_ops.Substr(
    input=""abc"",
    pos=tf.constant([],dtype=tf.int32),
    len=tf.constant([],dtype=tf.int32),
    unit='BYTE',
    name=None
)
```


### Relevant log output

Release build: Outputs nothing

Debug build:
```shell
python: external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorBroadcasting.h:156: Eigen::TensorEvaluator<const Eigen::TensorBroadcastingOp<const Eigen::array<long, 1>, const Eigen::TensorMap<Eigen::Tensor<const int, 1, 1>, 16>>, Eigen::DefaultDevice>::TensorEvaluator(const XprType &, const Device &) [Derived = const Eigen::TensorBroadcastingOp<const Eigen::array<long, 1>, const Eigen::TensorMap<Eigen::Tensor<const int, 1, 1>, 16>>, Device = Eigen::DefaultDevice]: Assertion `input_dims[i] > 0' failed.
Aborted (core dumped)
```
",https://github.com/Sehun0819,2024-02-23T13:48:20Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63035,SVDF layer implementation compatible with TFLiteâ€™s SVDF operator,"Although TFLite has a built-in SVDF operator (as listed [here](https://www.tensorflow.org/mlir/tfl_ops#tflsvdf_tflsvdfop), and whose implementation can be seen [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/internal/reference/svdf.h)), currently, Tensorflow doesn't have a keras layer implementation for the SVDF operation.
I was wondering what would be the sequence of operations (using Tensorflow's Python library) needed so that they could be fused and recognized as an SVDF operator after converting to TFLite.",https://github.com/VictorDominguite,2024-02-23T13:33:04Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63034,`tf.raw_ops.AvgPool`: negative kernel size is not checked at shape inference step,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.17

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04 LTS

### Mobile device

_No response_

### Python version

3.11.7

### Bazel version

6.5.0

### GCC/compiler version

clang 16

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Currently shape inference step of `tf.raw_ops.AvgPool` allows negative kernel size.
Note that debug build rejects it [here](https://github.com/tensorflow/tensorflow/blob/7ba14e559de0112cbf59dc6db6f8c6a18283642a/tensorflow/core/framework/common_shape_fns.cc#L1393-L1394):
```C++
  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDims(
      c, in_rows_dim, kernel_rows, stride_rows, padding, &output_rows));
```
, where `kernel_rows` is converted to `DimensionOrConstant` and ends up with assertion failure [here](https://github.com/tensorflow/tensorflow/blob/7ba14e559de0112cbf59dc6db6f8c6a18283642a/tensorflow/core/framework/shape_inference.h#L890-L895):
```C++
inline DimensionOrConstant::DimensionOrConstant(int64_t val) : val(val) {
  DCHECK(val >= 0 || val == InferenceContext::kUnknownDim)
      << ""Dimension must be non-negative or equal to ""
         ""InferenceContext::kUnknownDim but got ""
      << val;
}
```


### Standalone code to reproduce the issue

```Python
import tensorflow as tf

tf.compat.v1.disable_eager_execution()

x = tf.raw_ops.AvgPool(
    value=tf.random.normal([1,1,1,1]),
    ksize=[1,-2,1,1],
    strides=[1,1,1,1],
    padding=""SAME"",
    data_format='NHWC',
    name=None
)

print(x)
```


### Relevant log output

Release Build:
```shell
Tensor(""AvgPool:0"", shape=(1, 1, 1, 1), dtype=float32)
```

Debug Build:
```shell
2024-02-23 22:18:43.783609: F ./tensorflow/core/framework/shape_inference.h:891] Check failed: val >= 0 || val == InferenceContext::kUnknownDim Dimension must be non-negative or equal to InferenceContext::kUnknownDim but got -2
Aborted (core dumped)
```
",https://github.com/Sehun0819,2024-02-23T13:29:12Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63033,`tf.raw_ops.ConjugateTranspose`: negative value of `perm` can lead to out-of-bounds read,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.17

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04 LTS

### Mobile device

_No response_

### Python version

3.11.7

### Bazel version

6.5.0

### GCC/compiler version

clang 16

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

In `tf.raw_ops.ConjugateTranspose`, negative value of `perm` can lead to out-of-bounds read.
[Here](https://github.com/tensorflow/tensorflow/blob/617b5e97d6a9a71e1972dfe6fead5bf460094658/tensorflow/core/kernels/transpose_functor_cpu.cc#L52),
```C++
        i_idx += ratio * in_strides[perm[i]];
```
as there is no guard which checks validity of `perm`, when its value is -1 `in_strides[perm[i]]` can be an out-of-bounds reading(I guess -1 would be interpreted as an `SIZE_T_MAX` or something).
Note that the below code ends up with absl assertion failure in debug build.

### Standalone code to reproduce the issue

```Python
import tensorflow as tf

tf.raw_ops.ConjugateTranspose(
    x=tf.random.normal([2]),
    perm=[-1])
```


### Relevant log output

Release Build:
```shell
    Outputs nothing
```

Debug Build:
```shell
python: external/com_google_absl/absl/container/inlined_vector.h:363: auto absl::InlinedVector<long, 8>::operator[](size_type)::(anonymous class)::operator()() const [T = long, N = 8, A = std::allocator<long>]: Assertion `false && ""i < size()""' failed.
Aborted (core dumped)
```
",https://github.com/Sehun0819,2024-02-23T13:09:32Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63032,add go protobuf-files,,https://github.com/clmforever,2024-02-23T07:35:43Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63031,Confusing result of tf.argsort/argmax/argmin/ given a boolean axis,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.15.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

These three APIs tf.argsort/argmax/argmin will accept boolean axis such as True and False, which confuses me. Indeed, the documentation claims that the type of axis for tf.argmax and tf.argmin should be integer (https://www.tensorflow.org/api_docs/python/tf/math/argmax, https://www.tensorflow.org/api_docs/python/tf/math/argmin).

Moreover, tf.argsort can also accept string variable.

Taking a closer look, I find this code: https://github.com/tensorflow/tensorflow/blob/74cafb3ee7ce22dc2593127a2a6d8e78425e2640/tensorflow/python/ops/sort_ops.py#L179

It seems that argsort will convert any value of axis to integer using the `int()` call. 
However, such silent handling might make user confuse because the actual behavior deviates from the documentation.


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
values = tf.constant([[3,1,4,1,5,9,2,6], [3,4,5,1,2,3,4,0]])
axis = True
print(tf.argsort(values,axis))  # tf.Tensor([[1 3 0 2] [3 0 1 2]], shape=(2, 4), dtype=int32)
print(tf.argmax(values,axis))  # tf.Tensor([2 2], shape=(2,), dtype=int64)
print(tf.argmin(values,axis))  # tf.Tensor([1 3], shape=(2,), dtype=int64)
axis = '-1'
print(tf.argsort(values, axis))  # tf.Tensor([[1 3 0 2] [3 0 1 2]], shape=(2, 4),dtype=int32)
```


### Relevant log output

_No response_",https://github.com/drewshark,2024-02-22T22:00:23Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63030,[oneDNN] Add oneDNN version of SparseMatrixMatMul (v2),"This is version 2 of #62883, which should fix the build on ARM64.

Adds `_MklNativeSparseMatrixMatMul` and its accompanying kernel, which uses oneDNN to multiply a CSR sparse matrix by a dense tensor. The op is enabled with an environment variable (`TF_ENABLE_ONEDNN_SPMM`), so is entirely opt-in. It also includes tests and a benchmark, which we've used below to measure its performance against the existing kernel.

The performance looks promising particularly for larger shapes, and is optimized to use the AVX2 and AVX512 ISAs. These results were collected using the new benchmark in `tensorflow/core/kernels/mkl/mkl_sparse_matrix_matmul_op_benchmark.cc` on an Intel Xeon Platinum 8480 with hyperthreading enabled. To minimize NUMA effects, we bound it to the first socket.

Configuration (NNZ_M_K_N) | Eigen Time (ns) | oneDNN Time (ns) | Ratio
-- | -- | -- | --
128_8_512_1 | 15300 | 18598 | 0.82
128_16_512_1 | 14778 | 18551 | 0.80
128_128_512_1 | 18613 | 19165 | 0.97
128_4096_4096_1 | 151525 | 35904 | 4.22
1024_4096_4096_1 | 161593 | 37041 | 4.36
16384_4096_4096_1 | 163055 | 49355 | 3.30
128_8_1024_16 | 17307 | 18420 | 0.94
128_16_1024_16 | 17765 | 18678 | 0.95
128_128_1024_16 | 19247 | 19200 | 1.00
128_4096_4096_128 | 160341 | 140894 | 1.14
128_4096_4096_1024 | 181590 | 156980 | 1.16
1024_8_1024_16 | 24265 | 19502 | 1.24
1024_16_1024_16 | 24223 | 20448 | 1.18
1024_128_1024_16 | 26013 | 20396 | 1.28
1024_4096_4096_128 | 157612 | 139688 | 1.13
1024_4096_4096_1024 | 177549 | 160973 | 1.10
16384_8_1024_16 | 153005 | 36643 | 4.18
16384_16_1024_16 | 152853 | 36597 | 4.18
16384_128_1024_16 | 153600 | 31928 | 4.81
16384_4096_4096_128 | 166061 | 142494 | 1.17
16384_4096_4096_1024 | 244243 | 194536 | 1.26
16384_4096_4096_4096 | 654950 | 536546 | 1.22
100_1_1000000_100 | 18230 | 19991 | 0.91
200_1_2000000_100 | 20509 | 20818 | 0.99
400_1_4000000_100 | 23023 | 21638 | 1.06
400_4_1000000_100 | 22164 | 21349 | 1.04
800_4_2000000_100 | 26180 | 23374 | 1.12
1600_4_4000000_100 | 40538 | 28622 | 1.42
800_8_1000000_100 | 27015 | 23231 | 1.16
1600_8_2000000_100 | 39953 | 27894 | 1.43
3200_8_4000000_100 | 77708 | 42709 | 1.82",https://github.com/matthew-olson-intel,2024-02-22T20:34:18Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63029,How the data member `data_` of TensorBuffer is destroyed?,"From the `TensorBuffer ` definition, I notice there is a member `data_`
https://github.com/tensorflow/tensorflow/blob/b7ee894eba3b725eafdd70b088029e907f7943c7/tensorflow/core/framework/tensor.h#L108

I am curious about how this void pointer will be destroyed?

I find `RefCounted::Unref` has the logic of `delete`, especially the following line:

https://github.com/tensorflow/tensorflow/blob/b7ee894eba3b725eafdd70b088029e907f7943c7/third_party/xla/third_party/tsl/tsl/platform/refcount.h#L336

but it seems the above line did not delete what the void pointer `data_` is pointing to.",https://github.com/shizidushu,2024-02-22T18:57:36Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63028,Reverts a0d7ace8e2fd948920a0fee3618cb4fcc98eb513,"Reverts a0d7ace8e2fd948920a0fee3618cb4fcc98eb513
",https://github.com/kanglant,2024-02-22T18:53:04Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63027,Tensorflow cannot find libdevice.so consistently,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.14.0

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04.1

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.8, cuDNN 8.7.0.84

### GPU model and memory

_No response_

### Current behavior?

I am running inference using Tensorflow 2.14 installed via `pip` on a model written for Tensorflow 2.4. The model works but sometimes crashes unexpectedly. Tensorflow log suggests it cannot find a file at the path throwing an error:

`${CONDA_PREFIX}/envs/dp5_cascade/lib/python3.10/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2/../../nvidia/cuda_nvcc/nvvm/libdevice/libdevice.10.bc:-1:-1: Could not open input file: Not a directory`

or inserts a mystery character and then also throws an error:

`2024-02-22 14:00:25.171585: F tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/utils.cc:32] /home/rk582/miniconda3/envs/dp5_cascade/lib/python3.10/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2ï¿½/../../nvidia/cuda_nvcc/nvvm/libdevice/libdevice.10.bc:-1:-1: Could not open input file: No such file or directory`

However, there is definitely a file at `${CONDA_PREFIX}/envs/dp5_cascade/lib/python3.10/site-packages/nvidia/cuda_nvcc/nvvm/libdevice/libdevice.10.bc` so I do not know why would the code look for a file in such a roundabout way.

Are there any environment variables one can set to ensure consistent function?

nb I am dealing with a legacy code base with the author long gone and it is too hard to untangle it from a larger package due to their design decisions


### Standalone code to reproduce the issue

```shell
from tensorflow.keras.models import load_model


model = load_model(path_to_model, custom_objects = (some custom objects), compile = False)
model.compile()

yhat = model(input)
```


### Relevant log output

```shell
2024-02-21 16:44:51.345095: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-02-21 16:44:51.366345: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-02-21 16:44:51.366366: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-02-21 16:44:51.366380: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-02-21 16:44:51.370317: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-21 16:44:52.290366: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-02-21 16:44:52.293186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-02-21 16:44:52.293275: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-02-21 16:44:52.294092: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-02-21 16:44:52.294204: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-02-21 16:44:52.294275: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-02-21 16:44:52.330931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-02-21 16:44:52.331051: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-02-21 16:44:52.331135: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-02-21 16:44:52.331200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5503 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6
==========================

2024-02-21 16:44:52.658956: F tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/utils.cc:32] /home/rk582/miniconda3/envs/dp5_cascade/lib/python3.10/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2ï¿½/../../nvidia/cuda_nvcc/nvvm/libdevice/libdevice.10.bc:-1:-1: Could not open input file: No such file or directory
```
",https://github.com/ruslankotl,2024-02-22T16:04:42Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63026,Support legalization of tf.SplitV op for dynamic shapes,"Hi all,

This patch implements the legalization of `tf.SplitV` op for dynamic shapes, which is helpful for dynamic shape compilation
May I get reviews for it?

- Testing:  the following tests all passed
```
   tensorflow/compiler/mlir/tf2xla/tests:all_tests \
   tensorflow/compiler/mlir/tensorflow/tests:all_tests
```

Thanks.
Best regards,
Jie",https://github.com/DamonFool,2024-02-22T08:03:19Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63025,Failure in convert Gemma 2B models to TfLite,"I tried converting Google Gemma 2B models to TfLite. Found it ending in failure 

### 1. System information

-  Ubuntu 22.04
- TensorFlow installation (installed with keras-nlp) :
- TensorFlow library (installed with keras-nlp):

### 2. Code
```
import os
import keras
import os
import numpy as np
import keras_nlp
import tensorflow as tf
import tensorflow_datasets as tfds
import tensorflow_text as tf_text
from tensorflow import keras
from tensorflow.lite.python import interpreter
import time
from keras_nlp.backend import ops

os.environ[""KAGGLE_USERNAME""] = ""rag""
os.environ[""KAGGLE_KEY""] = 'e7c'
os.environ[""KERAS_BACKEND""] = ""tensorflow""  # Or ""tensorflow"" or ""torch"".

preprocessor = keras_nlp.models.GemmaCausalLMPreprocessor.from_preset('gemma_2b_en', sequence_length=4096, add_end_token=True
)
generator = keras_nlp.models.GemmaCausalLM.from_preset(""gemma_2b_en"")

def run_inference(input, generate_tflite):
  interp = interpreter.InterpreterWithCustomOps(
      model_content=generate_tflite,
      custom_op_registerers=tf_text.tflite_registrar.SELECT_TFTEXT_OPS)
  interp.get_signature_list()

  preprocessor_output = preprocessor.generate_preprocess(
    input, sequence_length=preprocessor.sequence_length
  )
  generator = interp.get_signature_runner('serving_default')
  output = generator(preprocessor_output)
  output = preprocessor.generate_postprocess(output[""output_0""])
  print(""\nGenerated with TFLite:\n"", output)

generate_function = generator.make_generate_function()
concrete_func = generate_function.get_concrete_function({
  ""token_ids"": tf.TensorSpec([None, 4096]),
  ""padding_mask"": tf.TensorSpec([None, 4096])
})


converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func],
                                                            generator)
converter.target_spec.supported_ops = [
  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.
  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.
]
converter.allow_custom_ops = True
converter.target_spec.experimental_select_user_tf_ops = [""UnsortedSegmentJoin"", ""UpperBound""]
converter._experimental_guarantee_all_funcs_one_use = True
generate_tflite = converter.convert()
run_inference(""I'm enjoying a"", generate_tflite)

with open('unquantized_mistral.tflite', 'wb') as f:
  f.write(generate_tflite)
```
### 3. Failure after conversion

I am getting this error:

tensorflow/core.py"":65:1))))))))))))))))))))))))))]): error: missing attribute 'value'
LLVM ERROR: Failed to infer result type(s).
Aborted (core dumped)

### 5. (optional) Any other info / logs

```
2024-02-22 06:34:41.094712: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.
2024-02-22 06:34:41.094742: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.
2024-02-22 06:34:41.095691: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp58p378bn
2024-02-22 06:34:41.140303: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }
2024-02-22 06:34:41.140329: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp58p378bn
2024-02-22 06:34:41.233389: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled
2024-02-22 06:34:41.264724: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.
2024-02-22 06:34:43.697440: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp58p378bn
2024-02-22 06:34:44.189111: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 3093423 microseconds.
2024-02-22 06:34:45.009212: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
loc(fused[""ReadVariableOp:"", callsite(""decoder_block_0_1/attention_1/attention_output_1/Cast/ReadVariableOp@__inference_generate_step_12229""(""/workspace/gem.py"":38:1) at callsite(""/usr/local/lib/python3.10/dist-packages/keras_nlp/models/gemma/gemma_causal_lm.py"":258:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras_nlp/models/gemma/gemma_causal_lm.py"":235:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras_nlp/models/gemma/gemma_causal_lm.py"":212:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras_nlp/models/gemma/gemma_causal_lm.py"":214:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"":118:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"":816:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"":118:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"":42:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"":157:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras_nlp/models/gemma/gemma_decoder_block.py"":147:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"":118:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"":816:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"":118:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"":42:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"":157:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras_nlp/models/gemma/gemma_attention.py"":193:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"":118:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py"":816:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"":118:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py"":42:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py"":157:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/einsum_dense.py"":218:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/ops/numpy.py"":2414:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/numpy.py"":90:1 at callsite(""/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/numpy.py"":91:1 at ""/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py"":65:1))))))))))))))))))))))))))]): error: missing attribute 'value'
LLVM ERROR: Failed to infer result type(s).
Aborted (core dumped)
```
",https://github.com/RageshAntonyHM,2024-02-22T07:33:01Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63024,How to use Hand pose detection module in iOS?,"I want to use Hand Pose Detection module in iOS (Swift), So which pod I use or any reference source code available.",https://github.com/vnanaware111,2024-02-22T06:40:45Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63023,Pallas like kernel language for TensorFlow,"### Issue type

Feature Request

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.15

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

JAX provided [Pallas](https://jax.readthedocs.io/en/latest/pallas/tpu.html) to write TPU and GPU kernel. It would be great if TensorFlow had a similar feature.

",https://github.com/edwardyehuang,2024-02-22T04:33:47Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63022,tfl: mul_test: optimize the MultiDimBroadcastSubshard tests,"Optimize to avoid doing duplicate calculation to speed up the cases *MultiDimBroadcastSubshard*.

This improves the execution time for example from 1m11.090s to 1m10.645s.",https://github.com/keyonjie,2024-02-22T00:26:45Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63021,load_model() cannot load model from previous version,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.14 and tf 2.15

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Hello, 

I was trying to load a model I previously saved with tf 2.14, and got the displayed error. I realized that the model was saved with tf 2.14, and the environment I was trying to load the model in was tf 2.15. I'm not sure if this is an expected behavior, but it seemed odd since the version difference wasn't that big.

### Standalone code to reproduce the issue

```shell
# previously saved model with tf 2.14
# import tensorflow as tf
# from tensorflow import keras
# import numpy as np

# # print version
# print(tf.__version__)

# # random data
# data = np.random.random((100, 10))
# labels = np.random.random((100, ))

# # simple model
# normalizer = keras.layers.Normalization()
# normalizer.adapt(data)
# model = keras.Sequential()
# model.add(normalizer)
# model.add(keras.layers.Dense(10))
# model.add(keras.layers.Dense(1))
# model.compile(loss='mean_squared_error', optimizer='adam')
# model.fit(data, labels, epochs=10, verbose=2)
# model.save('test.keras')


### loading with tf 2.15 ###
import tensorflow as tf
from tensorflow import keras

# print version
print(tf.__version__)

# load model
model = keras.models.load_model('test.keras')
```


### Relevant log output

```shell
2.15.0

Traceback (most recent call last):
  File ""/work/users/e/n/enesk/phakinpro/test_load.py"", line 8, in <module>
    model = keras.models.load_model('test.keras')
  File ""/nas/longleaf/home/enesk/miniforge3/envs/tf/lib/python3.9/site-packages/keras/src/saving/saving_api.py"", line 254, in load_model
    return saving_lib.load_model(
  File ""/nas/longleaf/home/enesk/miniforge3/envs/tf/lib/python3.9/site-packages/keras/src/saving/saving_lib.py"", line 281, in load_model
    raise e
  File ""/nas/longleaf/home/enesk/miniforge3/envs/tf/lib/python3.9/site-packages/keras/src/saving/saving_lib.py"", line 246, in load_model
    model = deserialize_keras_object(
  File ""/nas/longleaf/home/enesk/miniforge3/envs/tf/lib/python3.9/site-packages/keras/src/saving/serialization_lib.py"", line 728, in deserialize_keras_object
    instance = cls.from_config(inner_config)
  File ""/nas/longleaf/home/enesk/miniforge3/envs/tf/lib/python3.9/site-packages/keras/src/engine/sequential.py"", line 471, in from_config
    model.add(layer)
  File ""/nas/longleaf/home/enesk/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/trackable/base.py"", line 204, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/nas/longleaf/home/enesk/miniforge3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py"", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/nas/longleaf/home/enesk/miniforge3/envs/tf/lib/python3.9/site-packages/keras/src/layers/preprocessing/normalization.py"", line 188, in build
    raise ValueError(
ValueError: All `axis` values to be kept must have known shape. Got axis: (-1,), input shape: [None, None], with unknown axis at index: 1
```
",https://github.com/eneskelestemur,2024-02-21T23:21:33Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63019,Dataset is never fully read when caching to disk,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.13.1

### Custom code

Yes

### OS platform and distribution

Windows 11

### Mobile device

_No response_

### Python version

Python 3.9.13

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When displaying the dataset elements for viewing with either `train_data.take(1)` or `train_data.take(1).cache()` it always shows the message ""The calling iterator did not fully read the dataset being cached..."".

The following has already been tried, but the same message always appears:

```python
# train_data = train_data.cache()
# train_data = train_data.take(1)
# train_data = train_data.take(1).cache()
# train_data = train_data.take(1).prefetch(tf.data.experimental.AUTOTUNE)
```
There is a similar problem but the bot closed it due to inactivity: #60174 


### Standalone code to reproduce the issue

```shell
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt

data, metadata = tfds.load(
    name='fashion_mnist',
    as_supervised=True,
    with_info=True)
train_data = data['train']
categories = metadata.features['label'].names

plt.suptitle('First Item')
for image, label_index in train_data.take(1):
    plt.imshow(image, cmap='binary')
    plt.xlabel(categories[label_index])
    plt.colorbar()
    plt.grid(visible=False)
    plt.show()
```


### Relevant log output

```shell
2024-02-21 14:07:32.650452: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
```
",https://github.com/vanskarner,2024-02-21T19:14:40Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63018,${BUILD_NUM_JOBS} not defined in TF lite building script leads to crash,"### Issue type

Build/Install

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.15.0

### Custom code

No

### OS platform and distribution

Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

in line 126 of file: `tensorflow/lite/tools/pip_package/build_pip_package_with_cmake.sh`
```
cmake --build . --verbose -j ${BUILD_NUM_JOBS} -t _pywrap_tensorflow_interpreter_wrapper
```
the variable `${BUILD_NUM_JOBS}` is never defined. When compilation fo TF lite is carried out with cmake (docker, native) there is no limit in the number of processes used for compilation. This leads to a massive RAM/swap usage and in some cases when these resources run out, a crash (with logged error: `Killed signal terminated program cc1plus`).

The `${BUILD_NUM_JOBS}` variable should be set earlier in the script or replaced with a `-j 4`.





### Standalone code to reproduce the issue

```shell
PYTHON=python3 tensorflow/lite/tools/pip_package/build_pip_package_with_cmake.sh native
```


### Relevant log output

_No response_",https://github.com/feranick,2024-02-21T18:27:02Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63017,Build/release Python 3.11 tflite-runtime MacOS wheels to PyPI,"### Issue type

Feature Request

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.14.0

### Custom code

Yes

### OS platform and distribution

MacOs

### Mobile device

_No response_

### Python version

4.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

We are currently needing to run automated jobs on MacOS using tflite-runtime and Python 3.11, but the wheels on Pypi only cover Linux.

### Standalone code to reproduce the issue

```shell
pip install tflite-runtime
```


### Relevant log output

```shell
ERROR: Could not find a version that satisfies the requirement tflite-runtime (from versions: none)
ERROR: No matching distribution found for tflite-runtime
```
",https://github.com/chatnord,2024-02-21T17:38:48Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63016,tf-lite CMake: add headers into sources to correctly install them,"The headers `delegate.h` and `delegate_options.h` were missing when tensorflow lite was installed with the GPU delegates using CMake.

This PR just add these 2 files into  `TFLITE_DELEGATES_GPU_SRCS` variable and it fixes the issue. It works because `TFLITE_DELEGATES_GPU_SRCS` is used to create `_ALL_TFLITE_SRCS` which is used to have `_ALL_TFLITE_HDRS` and then all headers from this variables are installed.",https://github.com/lbertho-gpsw,2024-02-21T15:13:00Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63015,[TFLite] Support for fully quantized fused custom operators,"Hi,

This PR adds support for fully quantized fused custom ops with two commits:
* The first one adds a `_tfl_no_side_effect` trait to mark a function as having no side-effect so that the dangling outputs are correctly pruned. This can also be done through the `tfl-post-quantize` pass with `enable-no-side-effect=custom_op_name=true`, the commit provides a way to do it directly from the Python API.
* The second one propagate the `_tfl_quant_trait` and `_tfl_no_side_effect` traits on a custom op as operator attribute instead of as a custom option of the custom operator.

We can then annotate a function as follow to have a fully quantizated fused op:
```python
def get_implements_signature():
    implements_signature = [
        'name: ""tan""',
        'attr {key: ""tfl_fusable_op"" value { b: true } }',
        'attr {key: ""_tfl_quant_trait"" value { s: ""fully_quantizable"" } }',
        'attr {key: ""_tfl_no_side_effect"" value { b: true } }',
    ]
    return "" "".join(implements_signature)


@tf.function(experimental_implements=get_implements_signature())
def tan_f(x):
    return tf.math.sin(x) / tf.math.cos(x)
```",https://github.com/Tessil,2024-02-21T14:48:57Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63014,Compilation error on macos with GPU delegate,"### Issue type

Build/Install

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.15.0

### Custom code

No

### OS platform and distribution

Macos 14.3.1

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

Apple clang 15.0.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I'm trying to build tensorflow-lite with the GPU delegates with CMake. It works well with Linux and Android (gcc), but for Macos (apple clang compiler) , I have a compilation error:
`tensorflow-lite/tensorflow/lite/delegates/gpu/api.cc:72:10: error: no matching function for call to 'visit'
  return std::visit(ObjectTypeGetter{}, object);`

It complains about using std::visit on a absl::variant.

My guess is that std::visit with gcc is more permissive than the standard about std::visit and allow to use it with not only std::variant but also with other variant-like. On the other side, Clang is not that permissive.

I tried with the source from the 2.15.0 and also with the sources of the latest commit.

### Standalone code to reproduce the issue

```shell
cd tensorflow/lite && cmake -B build -DTFLITE_ENABLE_GPU=ON && cmake --build build
```


### Relevant log output

```shell
/Users/lbertho/devel/.sx/build/tensorflow-lite/tensorflow/lite/delegates/gpu/api.cc:72:10: error: no matching function for call to 'visit'
  return std::visit(ObjectTypeGetter{}, object);
         ^~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX14.2.sdk/usr/include/c++/v1/variant:1753:26: note: candidate template ignored: substitution failure [with _Visitor = tflite::gpu::(anonymous namespace)::ObjectTypeGetter, _Vs = <const absl::variant<std::monostate, tflite::gpu::OpenGlBuffer, tflite::gpu::OpenGlTexture, tflite::gpu::CpuMemory, tflite::gpu::OpenClBuffer, tflite::gpu::OpenClTexture, tflite::gpu::VulkanBuffer, tflite::gpu::VulkanTexture> &>]: no matching function for call to '__as_variant'
constexpr decltype(auto) visit(_Visitor&& __visitor, _Vs&&... __vs) {
                         ^
/Users/lbertho/devel/.sx/build/tensorflow-lite/tensorflow/lite/delegates/gpu/api.cc:79:10: error: no matching function for call to 'visit'
         std::visit(ObjectValidityChecker{def.object_def.data_type}, object);
         ^~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX14.2.sdk/usr/include/c++/v1/variant:1753:26: note: candidate template ignored: substitution failure [with _Visitor = tflite::gpu::(anonymous namespace)::ObjectValidityChecker, _Vs = <const absl::variant<std::monostate, tflite::gpu::OpenGlBuffer, tflite::gpu::OpenGlTexture, tflite::gpu::CpuMemory, tflite::gpu::OpenClBuffer, tflite::gpu::OpenClTexture, tflite::gpu::VulkanBuffer, tflite::gpu::VulkanTexture> &>]: no matching function for call to '__as_variant'
constexpr decltype(auto) visit(_Visitor&& __visitor, _Vs&&... __vs) {
                         ^
/Users/lbertho/devel/.sx/build/tensorflow-lite/tensorflow/lite/delegates/gpu/api.cc:85:14: error: no matching function for call to 'holds_alternative'
      return std::holds_alternative<CpuMemory>(obj);
             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX14.2.sdk/usr/include/c++/v1/variant:1502:16: note: candidate template ignored: could not match 'std::variant' against 'absl::variant'
constexpr bool holds_alternative(const variant<_Types...>& __v) noexcept {
               ^
/Users/lbertho/devel/.sx/build/tensorflow-lite/tensorflow/lite/delegates/gpu/api.cc:87:14: error: no matching function for call to 'holds_alternative'
      return std::holds_alternative<OpenGlBuffer>(obj);
             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX14.2.sdk/usr/include/c++/v1/variant:1502:16: note: candidate template ignored: could not match 'std::variant' against 'absl::variant'
constexpr bool holds_alternative(const variant<_Types...>& __v) noexcept {
               ^
/Users/lbertho/devel/.sx/build/tensorflow-lite/tensorflow/lite/delegates/gpu/api.cc:89:14: error: no matching function for call to 'holds_alternative'
      return std::holds_alternative<OpenGlTexture>(obj);
             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX14.2.sdk/usr/include/c++/v1/variant:1502:16: note: candidate template ignored: could not match 'std::variant' against 'absl::variant'
constexpr bool holds_alternative(const variant<_Types...>& __v) noexcept {
               ^
/Users/lbertho/devel/.sx/build/tensorflow-lite/tensorflow/lite/delegates/gpu/api.cc:91:14: error: no matching function for call to 'holds_alternative'
      return std::holds_alternative<OpenClBuffer>(obj);
             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX14.2.sdk/usr/include/c++/v1/variant:1502:16: note: candidate template ignored: could not match 'std::variant' against 'absl::variant'
constexpr bool holds_alternative(const variant<_Types...>& __v) noexcept {
               ^
/Users/lbertho/devel/.sx/build/tensorflow-lite/tensorflow/lite/delegates/gpu/api.cc:93:14: error: no matching function for call to 'holds_alternative'
      return std::holds_alternative<OpenClTexture>(obj);
             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX14.2.sdk/usr/include/c++/v1/variant:1502:16: note: candidate template ignored: could not match 'std::variant' against 'absl::variant'
constexpr bool holds_alternative(const variant<_Types...>& __v) noexcept {
               ^
/Users/lbertho/devel/.sx/build/tensorflow-lite/tensorflow/lite/delegates/gpu/api.cc:95:14: error: no matching function for call to 'holds_alternative'
      return std::holds_alternative<VulkanBuffer>(obj);
             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX14.2.sdk/usr/include/c++/v1/variant:1502:16: note: candidate template ignored: could not match 'std::variant' against 'absl::variant'
constexpr bool holds_alternative(const variant<_Types...>& __v) noexcept {
               ^
/Users/lbertho/devel/.sx/build/tensorflow-lite/tensorflow/lite/delegates/gpu/api.cc:97:14: error: no matching function for call to 'holds_alternative'
      return std::holds_alternative<VulkanTexture>(obj);
             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX14.2.sdk/usr/include/c++/v1/variant:1502:16: note: candidate template ignored: could not match 'std::variant' against 'absl::variant'
constexpr bool holds_alternative(const variant<_Types...>& __v) noexcept {
```
",https://github.com/lbertho-gpsw,2024-02-21T14:45:55Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63013,tf.math.bincount incorrect with large values,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

v2.15.0

### Custom code

No

### OS platform and distribution

Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.0

### GPU model and memory

RTX 3090Ti

### Current behavior?

The `tf.math.bincount` function returns incorrect results with medium size values, even though those don't exceed int32. Using int64 seems to work around the bug, at least at the number ranges that I tested.

This problem seems to have been introduced between 2.13 and 2.14, but still exists with 2.15.

### Standalone code to reproduce the issue

```shell
The expected result of the following function is `100000`.


tf.reduce_sum(tf.math.bincount(tf.range(100000)))
```
```


### Relevant log output

```shell
>>> tf.reduce_sum(tf.math.bincount(tf.range(50000)))
<tf.Tensor: shape=(), dtype=int32, numpy=42950>
>>> tf.reduce_sum(tf.math.bincount(tf.range(45000)))
<tf.Tensor: shape=(), dtype=int32, numpy=45000>
>>> tf.reduce_sum(tf.math.bincount(tf.range(47000)))
<tf.Tensor: shape=(), dtype=int32, numpy=45692>
>>> tf.reduce_sum(tf.math.bincount(tf.range(47000), dtype=tf.int64))
<tf.Tensor: shape=(), dtype=int64, numpy=47000>
```
",https://github.com/cbreak-black,2024-02-21T13:04:28Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63012,Unit test failures with Python 3.12 and gcc,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

git HEAD

### Custom code

No

### OS platform and distribution

Ubuntu 20.04

### Mobile device

n/a

### Python version

3.12.1

### Bazel version

6.5.0

### GCC/compiler version

10.2.1

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current behavior?

The following tests fail
//tensorflow/python/eager:backprop_test_cpu
//tensorflow/python/eager/polymorphic_function:tracing_compilation_test
//tensorflow/python/eager:forwardprop_test_cpu
//tensorflow/python/saved_model:load_test_cpu
//tensorflow/python/eager/polymorphic_function:polymorphic_function_test_cpu

### Standalone code to reproduce the issue

```shell
bazel test --test_timeout=500,900,3000,-1 --copt=-flax-vector-conversions --test_env=TF2_BEHAVIOR=1 --define=tf_api_version=2 --test_size_filters=small,medium --test_lang_filters=py,cc --test_output=errors --verbose_failures=true --notest_verbose_timeout_warnings --action_env=PYTHON_BIN_PATH=/usr/local/bin/python3 --test_env=PORTSERVER_ADDRESS=@unittest-portserver --build_tag_filters=-no_oss,-oss_excluded,-oss_serial,-v1only,-benchmark-test,-no_aarch64,-gpu,-tpu,-no_oss_py39,-no_oss_py310 --test_tag_filters=-no_oss,-oss_excluded,-oss_serial,-v1only,-benchmark-test,-no_aarch64,-gpu,-tpu,-no_oss_py39,-no_oss_py310 --build_tests_only -- //tensorflow/... -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/go/... -//tensorflow/java/... -//tensorflow/python/integration_testing/... -//tensorflow/tools/toolchains/... -//tensorflow/lite/...
```


### Relevant log output

```shell
FAIL: test_functions_cleaned_LoadWithPython (__main__.SingleCycleTests)
SingleCycleTests.test_functions_cleaned_LoadWithPython
test_functions_cleaned_LoadWithPython(use_cpp_bindings=False)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/saved_model/load_test_cpu.runfiles/absl_py/absl/testing/parameterized.py"", line 314, in bound_param_test
    return test_method(self, **testcase_params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/saved_model/load_test_cpu.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 823, in decorator
    assert not obj_count_by_type, (
AssertionError: The following objects were newly created: Counter({'list': 330, 'Operation': 270, 'TensorShape': 147})

----------------------------------------------------------------------
Ran 2 tests in 1.571s

FAILED (failures=1, skipped=1)
```
",https://github.com/elfringham,2024-02-21T13:02:23Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63010,Load and do inference of model.hdf5 in c++,"### Issue type

Support

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.14.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

3.11.5

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Hi,
Please provide instructions on how to load a CNN model in C++ script to run and do inference.
Thanks

### Standalone code to reproduce the issue

```shell
-
```


### Relevant log output

_No response_",https://github.com/devahh,2024-02-21T09:51:49Z
github,https://api.github.com/repos/tensorflow/tensorflow/issues/63009,"CONV1D , MAX POOLING 1D","I want to embed tflite model in my mcu, but conv1D, MAX Pooling 1D was used in the model. But that function doesn't exist in the mutable ops list.

Going Googling, I saw the answer that Conv1D wraps to Conv2D automatically when converting from Stackoverflow to tflite(https://stackoverflow.com/questions/67481996/custom-op-is-replaced-by-another-ops).

So should I use 'conv2d' and 'maxpooling2D' for mutable ops when embedding my model (conv1D, with maxpooling1D)?",https://github.com/hammnii-study,2024-02-21T08:36:39Z
